[ { "title": "OpenCV - 33. 히스토그램", "url": "/posts/opencv-33/", "categories": "OpenCV", "tags": "OpenCV, Histogram", "date": "2022-04-29 00:12:00 +0900", "snippet": "히스토그램(Histogram)히스토그램이란 도수 분포표 중 하나로 데이터의 분포를 몇 개의 구간으로 나누고 각 구간에 속하는 데이터를 시각적으로 표현한 막대그래프입니다.이미지에서 사용하는 히스토그램은 X 축을 픽셀의 값으로 사용하고 Y 축을 해당 픽셀의 개수로 표현합니다.이미지의 픽셀값을 히스토그램으로 표현하면 이미지의 특성을 쉽게 확인할 수 있습니다.히스토그램은 다음과 같은 세 가지의 중요한 요소를 갖고 있습니다. 빈도 수(BINS): 히스토그램 그래프의 X 축 간격 차원 수(DIMS): 히스토그램을 분석할 이미지의 차원 범위(RANGE): 히스토그램 그래프의 X 축 범위빈도 수는 히스토그램의 X 축 간격입니다. 픽셀값의 범위는 0~255로 총 256개의 범위를 갖고 있으며, 빈도 수의 값이 8이라면 0 ~ 7, 8 ~ 15, …, 248 ~ 255의 범위로 총 32개의 막대가 생성됩니다.차원 수는 이미지에서 분석하고자 하는 색상 차원을 의미합니다. 그레이스케일은 단일 채널이므로 하나의 차원에 대해 분석할 수 있고 색상 이미지는 다중 채널이므로 세 개 이상의 차원에 대해 분석할 수 있습니다.범위는 이미지에서 측정하려는 픽셀값의 범위로서, 특정 픽셀값 영역에 대해서만 분석하게 하는 데 사용됩니다.메인 코드import cv2import numpy as npsrc = cv2.imread(\"image/32.jpg\")gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)result = np.zeros((src.shape[0], 256), dtype=np.uint8)hist = cv2.calcHist([gray], [0], None, [256], [0, 256])cv2.normalize(hist, hist, 0, result.shape[0], cv2.NORM_MINMAX)for x, y in enumerate(hist): cv2.line(result, (x, result.shape[0]), (x, result.shape[0] - y), 255)dst = np.hstack([gray, result])cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드src = cv2.imread(\"image/32.jpg\")gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)result = np.zeros((src.shape[0], 256), dtype=np.uint8)원본 이미지(src)와 그레이스케일(gray), 히스토그램 이미지(result)을 선언합니다.히스토그램 이미지는 N개의 개수를 갖는 256 분포로 사용할 예정이므로, 이미지 높이는 원본 이미지를 사용하며, 너비는 256을 사용합니다.hist = cv2.calcHist([gray], [0], None, [256], [0, 256])히스토그램은 히스토그램 계산 함수(cv2.calcHist)를 통해 분포를 계산할 수 있습니다.cv2.calcHist(연산 이미지, 특정 채널, 마스크, 히스토그램 크기, 히스토그램 범위)를 이용하여 히스토그램을 계산합니다.특정 채널은 차원 수(DIMS)를 설정합니다. 그레이스케일 이미지는 단일 채널이므로, 0을 사용합니다.마스크는 특정 영역에 대해서만 연산할 때 사용합니다. 해당 영역은 없으므로, None을 할당합니다.히스토그램 크기는 빈도 수(BINS)를 설정합니다. 픽셀의 범위는 0 ~ 255 이므로, [256]을 할당합니다.히스토그램 범위는 범위(RANGE)를 설정합니다. 예외 사항이 없으므로, 0 ~ 255의 범위를 계산하기 위해 [0, 256]을 할당합니다.cv2.normalize(hist, hist, 0, result.shape[0], cv2.NORM_MINMAX)히스토그램을 통해 연산된 결과는 정규화되지 않은 값입니다.그러므로, 정규화 함수(cv2.normalize)를 통해 값을 변경합니다.cv2.normalize(입력 배열, 결과 배열, alpha, beta, 정규화 기준)으로 값을 정규화합니다.cv2.NORM_MINMAX을 통해, 정규화 기준을 최솟값이 alpha가 되고, 최댓값이 beta가 되게 변경합니다.이 연산을 통해 최솟값은 0이 되며, 최댓값은 result.shape[0]이 됩니다.for x, y in enumerate(hist): cv2.line(result, (x, result.shape[0]), (x, result.shape[0] - y), 255)dst = np.hstack([gray, result])결과를 시각적으로 확인하기 위해, hist값을 result에 표시합니다.이후, gray와 result는 이미지 높이가 같으므로 병합 함수(np.hstack)로 이미지를 연결합니다.출력 결과" }, { "title": "OpenCV - 32. 비트 연산", "url": "/posts/opencv-32/", "categories": "OpenCV", "tags": "OpenCV, Bitwise", "date": "2022-04-29 00:12:00 +0900", "snippet": "비트 연산(Bitwise)비트 연산은 하나 또는 두 이미지에 대해 비트 연산을 수행합니다.Numpy 클래스의 비트 연산과 동일한 의미와 결과를 갖습니다.또한, 비트 연산 표현(&amp;, | 등)을 통해 Mat 클래스 간의 연산을 수행할 수 있습니다.메인 코드import numpy as npimport cv2src = cv2.imread(\"image/31.jpg\")gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)_, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)_and = cv2.bitwise_and(gray, binary)_or = cv2.bitwise_or(gray, binary)_xor = cv2.bitwise_xor(gray, binary)_not = cv2.bitwise_not(gray)src = np.concatenate((np.zeros_like(gray), gray, binary, np.zeros_like(gray)), axis = 1)dst = np.concatenate((_and, _or, _xor, _not), axis = 1)dst = np.concatenate((src, dst), axis = 0)cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드src = cv2.imread(\"image/31.jpg\")gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)_, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)원본 이미지(src)와 그레이스케일(gray), 이진화(binary)을 선언합니다.연산 이미지는 그레이스케일 이미지와 127 임곗값을 갖는 이진화 이미지를 사용합니다._and = cv2.bitwise_and(gray, binary)_or = cv2.bitwise_or(gray, binary)_xor = cv2.bitwise_xor(gray, binary)_not = cv2.bitwise_not(gray)cv2.bitwise(연산 이미지1, 연산 이미지2)를 이용하여 비트 연산을 진행합니다.논리곱(bitwise_and), 논리합(bitwise_or), 배타적 논리합(bitwise_xor), 부정(bitwise_not) 등으로 연산이 가능합니다.논리곱 함수는 두 이미지의 요소별 논리곱을 계산합니다.연산 이미지1과 연산 이미지2의 값을 비트 단위로 파악하며, 해당 비트에 대해 AND 연산을 진행합니다.논리합 함수는 두 이미지의 요소별 논리합을 계산합니다.연산 이미지1과 연산 이미지2의 값을 비트 단위로 파악하며, 해당 비트에 대해 OR 연산을 진행합니다.배타적 논리합 함수는 두 이미지의 요소별 배타적 논리합을 계산합니다.연산 이미지1과 연산 이미지2의 값을 비트 단위로 파악하며, 해당 비트에 대해 XOR 연산을 진행합니다.논리합 함수는 두 이미지의 요소별 논리합을 계산합니다.연산 이미지1의 값을 비트 단위로 파악하며, 해당 비트에 대해 NOT 연산을 진행합니다.요소의 값이 각각 198, 255인 이미지를 배타적 논리합 비트 연산을 진행한다면 다음과 같습니다.198은 1100 0110이 되며, 255는 1111 1111이 됩니다.XOR 연산은 비트 값이 같으면 0, 다르다면 1이 됩니다.각 자리수 마다 값을 비교한다면 0011 1001이 됩니다.이 값을 10진수로 변경한다면, 57이 됩니다.그러므로, 이미지 요소 값은 57의 값으로 할당됩니다.src = np.concatenate((np.zeros_like(gray), gray, binary, np.zeros_like(gray)), axis = 1)dst = np.concatenate((_and, _or, _xor, _not), axis = 1)dst = np.concatenate((src, dst), axis = 0)dst = np.concatenate((src, number, dst), axis = 0)연결 함수(np.concatenate)로 이미지들을 연결합니다.결과 이미지는 다음과 같이 구성됩니다. None gray binary None _and _or _xor _not 출력 결과" }, { "title": "OpenCV - 31. 이미지 연산 - (2)", "url": "/posts/opencv-31/", "categories": "OpenCV", "tags": "OpenCV, Image Calculation", "date": "2022-04-28 00:12:00 +0900", "snippet": "이미지 연산(Image Calculation)이미지 연산은 하나 또는 둘 이상의 이미지에 대해 수학적인 연산을 수행합니다.Numpy 클래스의 배열 연산과 동일하거나 비슷한 의미와 결과를 갖습니다.또한, 대수적 표현(+, - 등)을 통해 Mat 클래스 간의 연산을 수행할 수 있습니다.메인 코드import numpy as npimport cv2src = cv2.imread(\"image/29.jpg\")number = np.ones_like(src) * 127_max = cv2.max(src, number)_min = cv2.min(src, number)_abs = cv2.absdiff(src, number)compare = cv2.compare(src, number, cv2.CMP_GT)src = np.concatenate((src, src, src, src), axis = 1)number = np.concatenate((number, number, number, number), axis = 1)dst = np.concatenate((_max, _min, _abs, compare), axis = 1)dst = np.concatenate((src, number, dst), axis = 0)cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드src = cv2.imread(\"image/29.jpg\")number = np.ones_like(src) * 127원본 이미지(src)와 연산 값(number)을 선언합니다.연산 이미지는 회색 이미지(127, 127, 127)를 사용합니다._max = cv2.max(src, number)_min = cv2.min(src, number)_abs = cv2.absdiff(src, number)compare = cv2.compare(src, number, cv2.CMP_GT)cv2.Calc(연산 이미지1, 연산 이미지2)를 이용하여 이미지 연산을 진행합니다.최댓값(max), 최솟값(min), 절댓값 차이(absdiff), 비교(compare) 등으로 연산이 가능합니다.최댓값 함수는 두 이미지의 요소별 최댓값을 계산합니다.최솟값 함수는 두 이미지의 요소별 최솟값을 계산합니다.최댓값 함수와 최솟값 함수는 정밀도에 따라 요소의 최댓값과 최솟값이 있으며, 최댓값을 넘어가거나 최솟값보다 낮아질 수 없습니다.절댓값 차이 함수는 두 이미지의 요소별 절댓값 차이를 계산합니다.덧셈 함수나 뺄셈 함수에서는 두 배열의 요소를 서로 뺄셈했을 때 음수가 발생하면 0을 반환했지만 절댓값 차이 함수는 이 값을 절댓값으로 변경해서 양수 형태로 반환합니다.비교 함수는 요소별 두 이미지의 요소별 비교 연산을 수행합니다.비교 결과가 True일 경우 요소의 값을 255로 변경하며, 비교 결과가 False일 경우 요소의 값을 0으로 변경합니다.src = np.concatenate((src, src, src, src), axis = 1)number = np.concatenate((number, number, number, number), axis = 1)dst = np.concatenate((_max, _min, _abs, compare), axis = 1)dst = np.concatenate((src, number, dst), axis = 0)연결 함수(np.concatenate)로 이미지들을 연결합니다.결과 이미지는 다음과 같이 구성됩니다. src src src src number1 number1 number2 number2 _max _min _abs compare 추가 정보비교 함수 플래그 플래그 설명 cv2.CMP_EQ src1와 src2의 요소가 같음 cv2.CMP_NE src1와 src2의 요소가 같지 않음 cv2.CMP_GT src1와 src2의 요소가 큼 cv2.CMP_GE src1와 src2의 요소가 크거나 같음 cv2.CMP_LT src1와 src2의 요소가 작음 cv2.CMP_LE src1와 src2의 요소가 작거나 같음 출력 결과" }, { "title": "OpenCV - 30. 이미지 연산 - (1)", "url": "/posts/opencv-30/", "categories": "OpenCV", "tags": "OpenCV, Image Calculation", "date": "2022-04-27 00:12:00 +0900", "snippet": "이미지 연산(Image Calculation)이미지 연산은 하나 또는 둘 이상의 이미지에 대해 수학적인 연산을 수행합니다.Numpy 클래스의 배열 연산과 동일하거나 비슷한 의미와 결과를 갖습니다.또한, 대수적 표현(+, - 등)을 통해 Mat 클래스 간의 연산을 수행할 수 있습니다.메인 코드import numpy as npimport cv2src = cv2.imread(\"image/29.jpg\")number1 = np.ones_like(src) * 127number2 = np.ones_like(src) * 2add = cv2.add(src, number1)sub = cv2.subtract(src, number1)mul = cv2.multiply(src, number2)div = cv2.divide(src, number2)src = np.concatenate((src, src, src, src), axis = 1)number = np.concatenate((number1, number1, number2, number2), axis = 1)dst = np.concatenate((add, sub, mul, div), axis = 1)dst = np.concatenate((src, number, dst), axis = 0)cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드src = cv2.imread(\"image/29.jpg\")number1 = np.ones_like(src) * 127number2 = np.ones_like(src) * 2원본 이미지(src)와 연산 값(number1, number2)을 선언합니다.연산 이미지는 회색 이미지(127, 127, 127)과 검은색 이미지(2, 2, 2)를 사용합니다.add = cv2.add(src, number1)sub = cv2.subtract(src, number1)mul = cv2.multiply(src, number2)div = cv2.divide(src, number2)cv2.Calc(연산 이미지1, 연산 이미지2)를 이용하여 이미지 연산을 진행합니다.덧셈(add), 뺄셈(subtract), 곱셈(multiply), 나눗셈(divide) 등으로 연산이 가능합니다.결괏값이 0보다 작다면, 0으로 반환되며, 결괏값이 255보다 크다면, 255로 반환됩니다.만약, 대수적 표현(+, - 등)을 통해 연산을 진행한다면, 오버플로우(Overflow)나 언더플로우(Underflow)가 발생합니다.즉, 0 - 2를 진행한다면 -1이 아닌, 255값이 됩니다.이미지는 uint8로, 256개의 공간(0 ~ 255)을 갖고 있습니다...., 253, 254, 255, 0, 1, 2, 3, ...이므로, 255값을 반환합니다.src = np.concatenate((src, src, src, src), axis = 1)number = np.concatenate((number1, number1, number2, number2), axis = 1)dst = np.concatenate((add, sub, mul, div), axis = 1)dst = np.concatenate((src, number, dst), axis = 0)연결 함수(np.concatenate)로 이미지들을 연결합니다.결과 이미지는 다음과 같이 구성됩니다. src src src src number1 number1 number2 number2 add sub mul div 추가 정보src = cv2.imread(\"image/29.jpg\")number1 = 127 ## np.ones_like(src) * 127number2 = 2 ## np.ones_like(src) * 2여기서 연산값을 np.ones_like(src) * N이 아닌 N으로 선언해도 연산이 가능합니다.단, 이 연산은 브로드캐스팅(Broadcasting)이 적용돼, [src.height, src.width, 1]이 됩니다.즉, 단일 채널 이미지가 되며 원본 이미지의 첫 번째 채널에만 연산됩니다.number1가 N이라면 \\([1, 0, 182] + N = [1 + N, 0, 182]\\) 가 됩니다.출력 결과" }, { "title": "OpenCV - 29. 원 검출", "url": "/posts/opencv-29/", "categories": "OpenCV", "tags": "OpenCV, Circle Detection", "date": "2022-04-26 00:12:00 +0900", "snippet": "원 검출(Circle Detection)원 검출 알고리즘도 허프 변환 알고리즘 중 하나인 허프 원 변환(Hough Circle Transform) 알고리즘을 활용해 원을 검출합니다.허프 원 변환 알고리즘은 앞서 배운 허프 선 변환 알고리즘과 비슷한 방식으로 동작합니다.허프 원 변환 알고리즘은 2차원이 아닌 3차원 누산 평면으로 검출합니다.각 차원은 원의 중심점 x, 원의 중심점 y, 원의 반경 r을 활용해 누산 평면을 구성합니다.누산 평면은 2차원 공간(x, y)에서 3차원 공간(a, b, r)으로 변환됩니다.허프 원 변환의 동작 방식은 이미지에서 가장자리를 검출합니다.3차원 히스토그램에서 돗수가 높은 (a, b, r)을 선택합니다. 하지만, 이 방법은 이미지에서 가장 긴 변의 길이가 N이라면 \\(N^3\\)바이트의 메모리를 필요로 합니다.이 방식은 필요한 메모리가 너무 많아 비효율적이므로, 메모리 문제와 느린 처리 속도를 해결하기 위해 2차원 방식을 사용합니다.이러한 문제로 인해 2단계로 나눠 계산합니다.먼저 가장자리에 그레이디언트 방법을 이용해 원의 중심점(a, b)에 대한 2차원 히스토그램을 선정합니다.모든 점에 대해 최소 거리에서 최대 거리까지 기울기의 선분을 따라 누산 평면의 모든 점을 증가시킵니다.또한 중심점을 선택하기 위해 중심점 후보군에서 임곗값보다 크고 인접한 점보다 큰 점을 중심점으로 사용합니다.선정된 중심점(a, b)와 가장자리의 좌표를 원의 방정식에 대입해 반지름 r의 1차원 히스토그램으로 판단하게 됩니다.히스토그램에 필요한 메모리가 줄어들어 이미지에서 가장 긴 변의 길이가 N이라면 \\(N^2 + N\\)바이트의 메모리를 필요로 합니다.OpenCV 원 검출 함수는 2단계 허프 변환(Two stage Hough Transform) 방법을 활용해 원을 검출합니다.메인 코드import cv2src = cv2.imread(\"image/28.jpg\")dst = src.copy()gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 100, param1 = 250, param2 = 10, minRadius = 80, maxRadius = 120)for i in circles[0]: cv2.circle(dst, (i[0], i[1]), i[2], (255, 255, 255), 5)cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드src = cv2.imread(\"image/28.jpg\")dst = src.copy()gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)이미지에서 직선을 검출하기 위해서, 전처리 작업을 진행합니다.원본 이미지(src)와 결과 이미지(dst)를 선언합니다.전처리를 진행하기 위해 그레이스케일 이미지(gray)를 사용합니다.circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 100, param1 = 250, param2 = 10, minRadius = 80, maxRadius = 120)cv2.HoughCircles(검출 이미지, 검출 방법, 해상도 비율, 최소 거리, 캐니 엣지 임곗값, 중심 임곗값, 최소 반지름, 최대 반지름)를 이용하여 원 검출을 진행합니다.검출 방법은 항상 2단계 허프 변환 방법(21HT, 그레이디언트)만 사용합니다.해상도 비율은 원의 중심을 검출하는 데 사용되는 누산 평면의 해상도를 의미합니다.인수를 1로 지정할 경우 입력한 이미지와 동일한 해상도를 가집니다. 즉, 입력 이미지 너비와 높이가 동일한 누산 평면이 생성됩니다.또한 인수를 2로 지정하면 누산 평면의 해상도가 절반으로 줄어 입력 이미지의 크기와 반비례합니다.최소 거리는 일차적으로 검출된 원과 원 사이의 최소 거리입니다. 이 값은 원이 여러 개 검출되는 것을 줄이는 역할을 합니다.캐니 엣지 임곗값은 허프 변환에서 자체적으로 캐니 엣지를 적용하게 되는데, 이때 사용되는 상위 임곗값을 의미합니다.하위 임곗값은 자동으로 할당되며, 상위 임곗값의 절반에 해당하는 값을 사용합니다.중심 임곗값은 그레이디언트 방법에 적용된 중심 히스토그램(누산 평면)에 대한 임곗값입니다. 이 값이 낮을 경우 더 많은 원이 검출됩니다.최소 반지름과 최대 반지름은 검출될 원의 반지름 범위입니다. 0을 입력할 경우 검출할 수 있는 반지름에 제한 조건을 두지 않습니다.최소 반지름과 최대 반지름에 각각 0을 입력할 경우 반지름을 고려하지 않고 검출하며, 최대 반지름에 음수를 입력할 경우 검출된 원의 중심만 반환합니다.for i in circles[0]: cv2.circle(dst, (i[0], i[1]), i[2], (255, 255, 255), 5)검출을 통해 반환되는 circles 변수는 (1, N, 3)차원 형태를 갖습니다.내부 차원의 요소로는 검출된 중심점(x, y)과 반지름(r)이 저장돼 있습니다.반복문을 활용해 circles 배열에서 중심점과 반지름을 반환할 수 있습니다.검출된 정보는 소수점을 포함합니다. 원 그리기 함수는 소수점이 포함되어도 사용할 수 있으므로, 형변환을 진행하지 않습니다.원 그리기 함수를 활용해 (x, y, r)의 원을 표시합니다.출력 결과" }, { "title": "OpenCV - 28. 직선 검출", "url": "/posts/opencv-28/", "categories": "OpenCV", "tags": "OpenCV, Line Detection", "date": "2022-04-25 00:12:00 +0900", "snippet": "직선 검출(Line Detection)직선 검출 알고리즘은 허프 변환(Hough Transform)을 활용해 직선을 검출합니다.허프 변환은 이미지에서 직선을 찾는 가장 보편적인 알고리즘입니다.이미지에서 선과 같은 단순한 형태를 빠르게 검출할 수 있으며, 직선을 찾아 이미지나 영상을 보정하거나 복원합니다.허프 선 변환은 이미지 내의 어떤 점이라도 선 집합의 일부일 수 있다는 가정하에 직선의 방정식을 이용해 직선을 검출한다.직선 검출은 직선의 방정식을 활용해 \\(y = ax + b\\)를 극좌표(ρ, θ)의 점으로 변환해서 사용합니다.극좌표 방정식으로 변환한다면 \\(p = xsinθ + ycosθ\\)이 되어, 직선과 원점의 거리(ρ)와 직선과 x축이 이루는 각도(θ)를 구할 수 있습니다.표준 허프 변환(Standard Hough Transform) &amp; 멀티 스케일 허프 변환(Multi-Scale Hough Transform)표준 허프 변환(Standard Hough Transform)은 입력 이미지(x, y 평면) 내의 점 \\(p\\)를 지나는 직선의 방정식을 구합니다.한 점을 통과하는 직선의 방정식을 구하면 기울기 \\(a\\)와 절편 \\(b\\)를 구할 수 있습니다.점 \\(p\\)에 대해 직선의 방정식을 수식으로 표현하면 그림 (a)와 같이 \\(y = ax + b\\) 로 표현할 수 있습니다.모든 점에 대해 모든 직선의 방정식을 구한다면 평면상에서 점들의 궤적이 생성되며, 동일한 궤적 위의 점은 직선으로 볼 수 있습니다.하지만, 한 점을 지나는 모든 직선의 방정식을 표현한다면 그림 (b)와 같이 기울기 \\(a\\)는 음의 무한대(-∞)에서 양의 무한대(∞)의 범위를 갖습니다.또한 수평인 영역에서 기울기 \\(a\\) 는 \\(0\\)의 값을 갖습니다.기울기와 절편을 사용해 모든 직선의 방정식을 표현하는 것은 좋은 방식이 아니므로, 삼각함수를 활용해 각 선을 극좌표(ρ, θ)의 점으로 변환해서 나타냅니다.멀티 스케일 허프 변환(Multi-Scale Hough Transform)은 표준 허프 변환을 개선한 방법입니다.검출한 직선의 값이 더 정확한 값으로 반환되도록, 거리(ρ)와 각도(θ)의 값을 조정해 사용합니다.두 값을 조정하는 방법으로 조금 더 우수한 검출을 할 수 있습니다.메인 코드import numpy as npimport cv2src = cv2.imread(\"image/27.jpg\")dst = src.copy()gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)canny = cv2.Canny(gray, 5000, 1500, apertureSize = 5, L2gradient = True)lines = cv2.HoughLines(canny, 0.8, np.pi / 180, 150, srn = 100, stn = 200, min_theta = 0, max_theta = np.pi)for i in lines: rho, theta = i[0][0], i[0][1] a, b = np.cos(theta), np.sin(theta) x0, y0 = a*rho, b*rho scale = src.shape[0] + src.shape[1] x1 = int(x0 + scale * -b) y1 = int(y0 + scale * a) x2 = int(x0 - scale * -b) y2 = int(y0 - scale * a) cv2.line(dst, (x1, y1), (x2, y2), (0, 0, 255), 2) cv2.circle(dst, (x0, y0), 3, (255, 0, 0), 5, cv2.FILLED)cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드src = cv2.imread(\"image/27.jpg\")dst = src.copy()gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)canny = cv2.Canny(gray, 5000, 1500, apertureSize = 5, L2gradient = True)이미지에서 직선을 검출하기 위해서, 전처리 작업을 진행합니다.원본 이미지(src)와 결과 이미지(dst)를 선언합니다.전처리를 진행하기 위해 그레이스케일 이미지(gray)와 케니 엣지 이미지(canny)를 사용합니다.케니 엣지 알고리즘의 임곗값은 각각 5000과 1500로 주요한 가장자리만 남깁니다.커널은 5의 크기와 L2그라디언트를 True로 사용합니다.lines = cv2.HoughLines(canny, 0.8, np.pi / 180, 150, srn = 100, stn = 200, min_theta = 0, max_theta = np.pi)cv2.HoughLines(검출 이미지, 거리, 각도, 임곗값, 거리 약수, 각도 약수, 최소 각도, 최대 각도)를 이용하여 직선 검출을 진행합니다.거리와 각도는 누산 평면에서 사용되는 해상도를 나타냅니다.거리의 단위는 픽셀을 의미하며, 0.0 ~ 1.0의 실수 범위를 갖습니다.각도의 단위는 라디안을 사용하며 0 ~ 180의 범위를 갖습니다.임곗값은 허프 변환 알고리즘이 직선을 결정하기 위해 만족해야 하는 누산 평면의 값을 의미합니다.누산 평면은 각도 × 거리의 차원을 갖는 2차원 히스토그램으로 구성됩니다.거리 약수와 각도 약수는 거리와 각도에 대한 약수(divisor)를 의미합니다.두 값 모두 0의 값을 인수로 활용할 경우, 표준 허프 변환이 적용되며, 하나 이상의 값이 0이 아니라면 멀티 스케일 허프 변환이 적용됩니다.최소 각도와 최대 각도는 검출할 각도의 범위를 설정합니다.for i in lines: rho, theta = i[0][0], i[0][1] a, b = np.cos(theta), np.sin(theta) x0, y0 = a*rho, b*rho scale = src.shape[0] + src.shape[1] x1 = int(x0 + scale * -b) y1 = int(y0 + scale * a) x2 = int(x0 - scale * -b) y2 = int(y0 - scale * a) cv2.line(dst, (x1, y1), (x2, y2), (0, 0, 255), 2) cv2.circle(dst, (x0, y0), 3, (255, 0, 0), 5, cv2.FILLED)검출을 통해 반환되는 lines 변수는 (N, 1, 2)차원 형태를 갖습니다.내부 차원의 요소로는 검출된 거리(rho)와 각도(theta)가 저장돼 있습니다.반복문을 활용해 lines 배열에서 거리와 각도를 반환할 수 있으며, 거리와 각도를 다시 직선의 방정식의 형태로 구성해야 결과 이미지 위에 표현할 수 있습니다.x와 y는 각각 \\(x = rcosθ\\), \\(r = sinθ\\)의 형태를 가지므로, 이 수식을 활용해 \\(x0\\)와 \\(y0\\)의 좌표를 구합니다.허프 변환 함수는 시작점과 도착점을 알려주는 함수가 아닌, 가장 직선일 가능성이 높은 거리와 각도를 검출합니다.검출된 정보는 직선의 방정식에 더 가깝습니다. 그러므로 출력 이미지 위에 표현하기 위해 \\(x0\\)와 \\(y0\\)를 직선의 방정식 선분을 따라 평행이동시켜 선을 그립니다.scale에 적절한 값을 지정해 이미지 밖으로 \\(x1, y1, x2, y2\\)를 할당합니다.선 그리기 함수와 원 그리기 함수를 활용해 (x1, y1) ~ (x2, y2)와 (x0, y0)의 위치를 표시합니다.점진성 확률적 허프 변환(Progressive Probabilistic Hough Transform)점진성 확률적 허프 변환(Progressive Probabilistic Hough Transform)은 또 다른 허프 변환 함수를 사용해 직선을 검출합니다.앞선 알고리즘은 모든 점에 대해 직선의 방정식을 세워 계산하기 때문에 비교적 많은 시간이 소모됩니다.기본적으로 점진성 확률적 허프 변환 알고리즘은 앞선 알고리즘을 최적화한 방식입니다.모든 점을 대상으로 직선의 방정식을 세우는 것이 아닌, 임의의 점 일부만 누적해서 계산합니다.일부의 점만 사용하기 때문에 확률적입니다.그러므로, 정확도가 높은 입력 이미지에 대해 검출에 드는 시간이 대폭 줄어듭니다.또한 이 알고리즘은 시작점과 끝점을 반환하므로 더 간편하게 활용할 수 있습니다.메인 코드import numpy as npimport cv2src = cv2.imread(\"image/27.jpg\")dst = src.copy()gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)canny = cv2.Canny(gray, 5000, 1500, apertureSize = 5, L2gradient = True)lines = cv2.HoughLinesP(canny, 0.8, np.pi / 180, 90, minLineLength = 10, maxLineGap = 100)for i in lines: cv2.line(dst, (i[0][0], i[0][1]), (i[0][2], i[0][3]), (0, 0, 255), 2)cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드lines = cv2.HoughLinesP(canny, 0.8, np.pi / 180, 90, minLineLength = 10, maxLineGap = 100)cv2.HoughLinesP(검출 이미지, 거리, 각도, 임곗값, 최소 선 길이, 최대 선 간격)를 이용하여 직선 검출을 진행합니다.검출 이미지, 거리, 각도, 임곗값은 앞선 허프 변환 알고리즘 함수와 동일한 의미를 갖습니다.최소 선 길이는 검출된 직선이 가져야 하는 최소한의 선 길이를 의미합니다. 이 값보다 낮은 경우 직선으로 간주하지 않습니다.최대 선 간격은 검출된 직선들 사이의 최대 허용 간격을 의미합니다. 이 값보다 간격이 좁은 경우 직선으로 간주하지 않습니다.for i in lines: cv2.line(dst, (i[0][0], i[0][1]), (i[0][2], i[0][3]), (0, 0, 255), 2)검출을 통해 반환되는 lines 변수는 (N, 1, 4)차원 형태를 갖습니다.마지막 차원에서 x1, y1, x2, y2의 순서로 시작점과 끝점을 표시합니다.별도의 계산 없이 선 그리기 함수를 활용해 (x1, y1) ~ (x2, y2)의 위치를 표시합니다.출력 결과멀티 스케일 허프 변환(Multi-Scale Hough Transform)점진성 확률적 허프 변환(Progressive Probabilistic Hough Transform)" }, { "title": "OpenCV - 27. 모폴로지 연산", "url": "/posts/opencv-27/", "categories": "OpenCV", "tags": "OpenCV, Morphological Calculate", "date": "2022-04-23 00:12:00 +0900", "snippet": "모폴로지 연산(Morphological Calculate)모폴로지 연산(Perspective Calculate)은 모폴로지 변환의 팽창(dilation)과 침식(erosion)을 기본 연산으로 사용해 고급 형태학을 적용하는 변환 연산입니다.입력 이미지가 이진화된 이미지라면 팽창과 침식 연산으로도 우수한 결과를 얻을 수 있습니다.하지만, 그레이스케일이나 다중 채널 이미지를 사용하는 경우 더 복잡한 연산을 필요로 합니다.이때 모폴로지 연산을 활용해 우수한 결과를 얻을 수 있습니다.열림(Opening) $$ open = dilate(erode(src)) $$ 팽창 연산자와 침식 연산자의 조합이며, 침식 연산을 적용한 다음, 팽창 연산을 적용합니다.열림 연산을 적용하면 침식 연산으로 인해 밝은 영역이 줄어들고 어두운 영역이 늘어납니다.줄어든 영역을 다시 복구하기 위해 팽창 연산을 적용하면 반대로 어두운 영역이 줄어들고 밝은 영역이 늘어납니다.이로 인해 스펙클(speckle)이 사라지면서 발생한 객체의 크기 감소를 원래대로 복구할 수 있습니다.닫힘(Closing) $$ close = erode(dilate(src)) $$ 팽창 연산자와 침식 연산자의 조합이며, 열림과 반대로 팽창 연산을 적용한 다음, 침식 연산을 적용합니다.닫힘 연산은 팽창 연산으로 인해 어두운 영역이 줄어들고 밝은 영역이 늘어납니다.늘어난 영역을 다시 복구하기 위해 침식 연산을 적용하면 밝은 영역이 줄어들고 어두운 영역이 늘어납니다.그로 인해 객체 내부의 홀(holes)이 사라지면서 발생한 크기 증가를 원래대로 복구할 수 있다.그레이디언트(Gradient) $$ gradient = dilate(src) - erode(src) $$ 팽창 연산자와 침식 연산자의 조합이며, 열림 연산이나 닫힘 연산과 달리 입력 이미지에 각각 팽창 연산과 침식 연산을 적용하고 감산을 진행합니다.입력 이미지와 비교했을 때 팽창 연산은 밝은 영역이 더 크며, 반대로 침식 연산은 밝은 영역이 더 작습니다.각각의 결과를 감산한다면 입력 이미지에 객체의 가장자리가 반환됩니다.그레이디언트는 밝은 영역의 가장자리를 분리하며 그레이스케일 이미지가 가장 급격하게 변하는 곳에서 가장 높은 결과를 반환합니다.탑햇(TopHat) $$ tophat = src - open(src) $$ 입력 이미지(src)와 열림(Opening)의 조합이며, 그레이디언트 연산과 비슷하게 입력 이미지에 열림 연산을 적용한 이미지를 감산합니다.열림 연산이 적용된 이미지는 스펙클이 사라지고 객체의 크기가 보존된 결과입니다.이 결과를 입력 이미지에서 감산한다면 밝은 영역이 분리되어 사라졌던 스펙클이나 작은 부분들이 표시됩니다.즉, 입력 이미지의 객체들이 제외되고 국소적으로 밝았던 부분들이 분리됩니다. Tip : 탑햇 연산은 열림 연산에서 사라질 요소들을 표시합니다.블랙햇(BlackHat) $$ blackhat = close(src) - src $$ 입력 이미지(src)와 닫힘(Closing)의 조합이며, 탑햇 연산과 비슷하게 닫힘 연산을 적용한 이미지에 입력 이미지를 감산합니다.닫힘 연산이 적용된 이미지는 객체 내부의 홀이 사라지고 객체의 크기가 보존된 결과입니다.이 결과에 입력 이미지를 감산한다면 어두운 영역이 채워져 사라졌던 홀 등이 표시됩니다.즉, 입력 이미지의 객체들이 제외되고 국소적으로 어두웠던 홀들이 분리됩니다. Tip : 블랙햇 연산은 닫힘 연산에서 사라질 요소들을 표시합니다.히트미스(HitMiss)히트미스(HitMiss) 연산은 앞의 연산자와 다른 형태입니다.히트미스 연산은 단일 채널 이미지에서 활용하며, 주로 이진화 이미지에 적용합니다.히트미스 연산은 이미지의 전경이나 배경 픽셀의 특정 패턴을 찾는 데 사용하는 이진 형태학으로서 구조 요소의 형태에 큰 영향을 받습니다.히트미스 연산의 커널은 기존 컨벌루션 커널과 다른 역할을 합니다.내부 요소의 값은 0 또는 1의 값만 의미가 있습니다.커널 내부의 0은 해당 픽셀을 고려하지 않는다는 의미이며, 1은 해당 요소를 유지하겠다는 의미입니다.이 특성 덕분에 히트미스 연산을 모서리(Corner)를 검출하는 데 활용하기도 합니다. Tip : 제한 조건 - 8-bit unsigned integers, 1-Channel메인 코드import numpy as npimport cv2src = cv2.imread('image/26.jpg')kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (9, 9))dst = cv2.morphologyEx(src, cv2.MORPH_OPEN, kernel, iterations=9)cv2.imshow('dst', dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드dst = cv2.morphologyEx(src, cv2.MORPH_OPEN, kernel, iterations=9)생성된 구조 요소(kernel)를 활용해 모폴로지 변환을 적용합니다.모폴로지 함수(cv2.morphologyEx)로 모폴로지 연산을 진행합니다.cv2.morphologyEx(원본 배열, 연산 방법, 구조 요소, 고정점, 반복 횟수, 테두리 외삽법, 테두리 색상)로 모폴로지 연산을 진행합니다.연산 방법에 따라, 모폴로지 연산 결과가 달라집니다. 예제의 연산 방법은 열림 연산입니다.연산 방법에는 기존 팽창 함수(cv2.dilate)와 침식 함수(cv2.erode)도 포함돼 있습니다.추가 정보연산 방법 종류 속성 의미 cv2.MORPH_DILATE 팽창 연산 cv2.MORPH_ERODE 침식 연산 cv2.MORPH_OPEN 열림 연산 cv2.MORPH_CLOSE 닫힘 연산 cv2.MORPH_GRADIENT 그레이디언트 연산 cv2.MORPH_TOPHAT 탑햇 연산 cv2.MORPH_BLACKHAT 블랙햇 연산 cv2.MORPH_HITMISS 히트미스 연산 출력 결과" }, { "title": "OpenCV - 26. 모폴로지 변환", "url": "/posts/opencv-26/", "categories": "OpenCV", "tags": "OpenCV, Morphological Transformation", "date": "2022-04-22 00:12:00 +0900", "snippet": "모폴로지 변환(Morphological Transformation)모폴로지 변환(Perspective Transformation)은 영상이나 이미지를 형태학적 관점에서 접근하는 기법을 의미합니다.모폴로지 변환은 주로 영상 내 픽셀값 대체에 사용됩니다. 이를 응용해서 노이즈 제거, 요소 결합 및 분리, 강도 피크 검출 등에 이용할 수 있습니다.집합의 포함 관계, 이동(translation), 대칭(reflection), 여집합(complement), 차집합(difference) 등의 성질을 사용합니다.기본적인 모폴로지 변환으로는 팽창(dilation)과 침식(erosion)이 있습니다.팽창과 침식은 이미지와 커널의 컨벌루션 연산이며, 이 두 가지 기본 연산을 기반으로 복잡하고 다양한 모폴로지 연산을 구현할 수 있습니다.팽창(Dilation) $$ dilate(x, y) = \\max_{\\rm (i, j)\\in kernel } src(x+i, y+j) $$ 팽창(dilation)은 커널 영역 안에 존재하는 모든 픽셀의 값을 커널 내부의 극댓값(local maximum)으로 대체합니다.즉, 구조 요소(element)를 활용해 이웃한 픽셀들을 최대 픽셀값으로 대체합니다.팽창 연산을 적용하면 어두운 영역이 줄어들고 밝은 영역이 늘어납니다.커널의 크기나 반복 횟수에 따라 밝은 영역이 늘어나 스펙클(speckle)이 커지며 객체 내부의 홀(holes)이 사라집니다.팽창 연산은 노이즈 제거 후 줄어든 크기를 복구하고자 할 때 주로 사용합니다.침식(Erosion) $$ erode(x, y) = \\min_{\\rm (i, j)\\in kernel } src(x+i, y+j) $$ 침식(erosion)은 커널 영역 안에 존재하는 모든 픽셀의 값을 커널 내부의 극솟값(local minimum)으로 대체합니다.즉, 구조 요소(element)를 활용해 이웃한 픽셀을 최소 픽셀값으로 대체합니다.침식 연산을 적용하면 밝은 영역이 줄어들고 어두운 영역이 늘어납니다.커널의 크기나 반복 횟수에 따라 어두운 영역이 늘어나 스펙클(speckle)이 사라지며, 객체 내부의 홀(holes)이 커집니다.침식 연산은 노이즈 제거에 주로 사용합니다.메인 코드import numpy as npimport cv2src = cv2.imread('image/25.jpg')kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (9, 9))dilate = cv2.dilate(src, kernel, anchor=(-1, -1), iterations=5)erode = cv2.erode(src, kernel, anchor=(-1, -1), iterations=5)dst = np.concatenate((src, dilate, erode), axis=1)cv2.imshow('dst', dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (9, 9))cv2.getStructuringElement()를 활용해 구조요소를 생성합니다.cv2.getStructuringElement(커널의 형태, 커널의 크기, 중심점)로 구조 요소을 생성합니다.커널의 형태는 직사각형(Rect), 십자가(Cross), 타원(Ellipse)이 있습니다.커널의 크기는 구조 요소의 크기를 의미합니다. 이때, 커널의 크기가 너무 작다면 커널의 형태는 영향을 받지 않습니다.고정점은 커널의 중심 위치를 나타냅니다. 필수 매개변수가 아니며, 설정하지 않을 경우 사용되는 함수에서 값이 결정됩니다. Tip : 고정점을 할당하지 않을 경우 조금 더 유동적인 커널이 됩니다.dilate = cv2.dilate(src, kernel, anchor=(-1, -1), iterations=5)erode = cv2.erode(src, kernel, anchor=(-1, -1), iterations=5)생성된 구조 요소를 활용해 모폴로지 변환을 적용합니다.팽창 함수(cv2.dilate)와 침식 함수(cv2.erode)로 모폴로지 변환을 진행합니다.cv2.dilate(원본 배열, 구조 요소, 고정점, 반복 횟수, 테두리 외삽법, 테두리 색상)로 팽창 연산을 진행합니다.cv2.erode(원본 배열, 구조 요소, 고정점, 반복 횟수, 테두리 외삽법, 테두리 색상)로 침식 연산을 진행합니다.팽창 함수와 침식 함수의 매개변수 순서와 의미는 동일합니다.단, 팽창 연산의 경우 밝은 영역이 커지며, 침식 연산의 경우 어두운 영역이 커집니다. Tip : 고정점을 (-1, -1)로 할당할 경우, 커널의 중심부에 고정점이 위치하게 됩니다.dst = np.concatenate((src, dilate, erode), axis=1)Numpy 함수 중 연결 함수(np.concatenate)로 원본 이미지, 팽창 결과, 침식 결과를 하나의 이미지로 연결합니다.np.concatenate(연결할 이미지 배열들, 축 방향)로 이미지를 연결합니다. Tip : axis=0으로 사용할 경우, 세로 방향으로 연결됩니다. Tip : OpenCV의 함수 중, 수평 연결 함수(cv2.hconcat)와 수직 연결 함수(cv2.vconcat)`로도 이미지를 연결할 수 있습니다. 출력 결과" }, { "title": "OpenCV - 25. 모멘트", "url": "/posts/opencv-25/", "categories": "OpenCV", "tags": "OpenCV, Moments", "date": "2022-04-21 00:12:00 +0900", "snippet": "모멘트(Moments)윤곽선(contour)이나 이미지(array)의 0차 모멘트부터 3차 모멘트까지 계산하는 알고리즘입니다.공간 모멘트(spatial moments), 중심 모멘트(central moments), 정규화된 중심 모멘트(normalized central moments), 질량 중심(mass center) 등을 계산할 수 있습니다.메인 코드import cv2src = cv2.imread(\"Image/23.png\")dst = src.copy()gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)ret, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)for i in contours: M = cv2.moments(i) cX = int(M['m10'] / M['m00']) cY = int(M['m01'] / M['m00']) cv2.circle(dst, (cX, cY), 3, (255, 0, 0), -1) cv2.drawContours(dst, [i], 0, (0, 0, 255), 2)cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드for i in contours: M = cv2.moments(i, False) cX = int(M['m10'] / M['m00']) cY = int(M['m01'] / M['m00'])cv2.moments()를 활용해 윤곽선에서 모멘트를 계산합니다.cv2.moments(배열, 이진화 이미지)을 의미합니다.배열은 윤곽선 검출 함수에서 반환되는 구조 또는 이미지를 사용합니다.이진화 이미지는 입력된 배열 매개변수가 이미지일 경우, 이미지의 픽셀 값들을 이진화 처리할지 결정합니다.이진화 이미지 매개변수에 참 값을 할당한다면 이미지의 픽셀 값이 0이 아닌 값은 모두 1의 값으로 변경해 모멘트를 계산합니다.모멘트 함수를 통해 면적, 평균, 분산 등을 간단하게 구할 수 있습니다.중심점을 구하는 공식은 다음과 같습니다.\\[\\bar{x}={m_{10}\\over m_{00}}, \\bar{y}={m_{01}\\over m_{00}}\\]위의 공식을 활용해 무게 중심(중심점)을 계산할 수 있습니다.추가 정보공간 모멘트(spatial moments)\\[m_{ij} = \\sum_{x,y}(array(x,y)\\times x^{i}y^{i})\\]중심 모멘트(central moments)\\[mu_{ij} = \\sum_{x,y}(array(x,y)\\times (x-\\bar{x})^{i}(y-\\bar{y})^{j})\\]정규화된 중심 모멘트(normalized central moments)\\[nu_{ij} = {mu_{ij}\\over m_{00}^{ \\frac{i+j}{2}+1} }\\]모멘트 구조\\[\\text{M} = \\begin{cases}\\text{0차 모멘트:}&amp;m_{00}\\\\\\text{1차 모멘트:}&amp;m_{10}, m_{01}\\\\\\text{2차 모멘트:}&amp;m_{11}, m_{20}, m_{02}\\\\\\text{3차 모멘트:}&amp;mu_{11}, mu_{20}, mu_{02}\\\\\\text{2차 중심 모멘트:}&amp;mu_{11}, mu_{20}, mu_{02}\\\\\\text{3차 중심 모멘트:}&amp;mu_{21}, mu_{12}, mu_{30}, mu_{03}\\\\\\text{2차 정규화된 중심 모멘트:}&amp;nu_{11}, nu_{20}, nu_{02}\\\\\\text{3차 정규화된 중심 모멘트:}&amp;nu_{21}, nu_{12}, nu_{30}, nu_{03}\\\\\\end{cases}\\]반환되지 않는 값\\[\\begin{cases}mu_{00} = m_{00}\\\\nu_{00} = 1\\\\mu_{01} = mu_{10} = nu_{01} = nu_{10} = 0\\end{cases}\\] Tip : 위 값들은 항상 같은 값을 가짐으로써 반환하지 않습니다.출력 결과" }, { "title": "OpenCV - 24. 블록 껍질", "url": "/posts/opencv-24/", "categories": "OpenCV", "tags": "OpenCV, ConvexHull", "date": "2022-04-20 00:12:00 +0900", "snippet": "블록 껍질(Convex Hull)윤곽선(points, contours)의 경계면을 둘러싸는 다각형을 구하는 알고리즘입니다.반환되는 결과는 윤곽선 검출 결과와 동일한 형식을 띄며, 스크랜스키(Sklansky) 알고리즘을 이용해 입력된 좌표들의 볼록한 외곽을 찾습니다.메인 코드import cv2src = cv2.imread(\"Image/23.png\")dst = src.copy()gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)ret, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)for i in contours: hull = cv2.convexHull(i, clockwise=True) cv2.drawContours(dst, [hull], 0, (0, 0, 255), 2)cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드for i in contours: hull = cv2.convexHull(i, clockwise=True) cv2.drawContours(dst, [hull], 0, (0, 0, 255), 2)cv2.convexHull()를 활용해 윤곽선에서 블록 껍질을 검출합니다.cv2.convexHull(윤곽선, 방향)을 의미합니다.윤곽선은 윤곽선 검출 함수에서 반환되는 구조를 사용합니다.방향은 검출된 볼록 껍질의 볼록점들의 인덱스 순서를 의미합니다.블록 껍질 함수는 단일 형태에서만 검출이 가능합니다.그러므로, 반복문을 활용해 단일 형태의 윤곽선 구조에서 블록 껍질을 검출합니다. Tip : 윤곽선 구조는 윤곽선 검출 함수의 반환값과 형태가 동일하다면, 임의의 배열에서도 검출이 가능합니다. Tip : 방향이 True라면 시계 방향, False라면 반시계 방향으로 정렬됩니다. 추가 정보블록 껍질 검출은 스크랜스키(Sklansky) 알고리즘을 사용합니다.경계 사각형의 정점(Vertex)을 검출합니다.경계면을 둘러싸는 다각형은 경계 사각형 내부에 포함되며, 해당 정점을 볼록점으로 사용합니다.영역 내부에도 다양한 윤곽점들이 존재하므로 여기서 볼록 껍질을 이루는 볼록점들을 선별해서 선택합니다.출력 결과" }, { "title": "OpenCV - 23. 코너 검출", "url": "/posts/opencv-23/", "categories": "OpenCV", "tags": "OpenCV, Corner Detection", "date": "2022-04-19 00:12:00 +0900", "snippet": "코너 검출(Good Features To Track)영상이나 이미지에서 코너를 검출하는 알고리즘입니다.코너 검출 알고리즘은 정확하게는 트래킹(Tracking) 하기 좋은 지점(특징)을 코너라 부릅니다.꼭짓점은 트래킹하기 좋은 지점이 되어 다각형이나 객체의 꼭짓점을 검출하는 데 사용합니다.메인 코드import cv2src = cv2.imread(\"Image/22.jpg\")dst = src.copy()gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 5, blockSize=3, useHarrisDetector=True, k=0.03)for i in corners: cv2.circle(dst, tuple(i[0]), 3, (0, 0, 255), 2)cv2.imshow(\"dst\", dst)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 5, blockSize=3, useHarrisDetector=True, k=0.03)cv2.goodFeaturesToTrack()를 활용해 윤곽선들의 이미지에서 코너를 검출합니다.cv2.goodFeaturesToTrack(입력 이미지, 코너 최댓값, 코너 품질, 최소 거리, 마스크, 블록 크기, 해리스 코너 검출기 유/무, 해리스 코너 계수)을 의미합니다.입력 이미지는 8비트 또는 32비트의 단일 채널 이미지를 사용합니다.코너 최댓값은 검출할 최대 코너의 수를 제한합니다. 코너 최댓값보다 낮은 개수만 반환합니다.코너 품질은 반환할 코너의 최소 품질을 설정합니다. 코너 품질은 0.0 ~ 1.0 사이의 값으로 할당할 수 있으며, 일반적으로 0.01 ~ 0.10 사이의 값을 사용합니다.최소 거리는 검출된 코너들의 최소 근접 거리를 나타내며, 설정된 최소 거리 이상의 값만 검출합니다.마스크는 입력 이미지와 같은 차원을 사용하며, 마스크 요솟값이 0인 곳은 코너로 계산하지 않습니다.블록 크기는 코너를 계산할 때, 고려하는 코너 주변 영역의 크기를 의미합니다.해리스 코너 검출기 유/무는 해리스 코너 검출 방법 사용 여부를 설정합니다.해리스 코너 계수는 해리스 알고리즘을 사용할 때 할당하며 해리스 대각합의 감도 계수를 의미합니다. Tip : 코너 품질에서 가장 좋은 코너의 강도가 1000이고, 코너 품질이 0.01이라면 10 이하의 코너 강도를 갖는 코너들은 검출하지 않습니다. Tip : 최소 거리의 값이 5일 경우, 거리가 5 이하인 코너점은 검출하지 않습니다.for i in corners: cv2.circle(dst, tuple(i[0]), 3, (0, 0, 255), 2)코너 검출 함수를 통해 corners가 반환되며, 이 배열안에 코너들의 좌표가 저장돼 있습니다.반복문을 활용해 dst에 빨간색 원으로 지점을 표시합니다.출력 결과" }, { "title": "OpenCV - 22. 다각형 근사", "url": "/posts/opencv-22/", "categories": "OpenCV", "tags": "OpenCV, Approx Poly", "date": "2022-04-18 00:12:00 +0900", "snippet": "다각형 근사(Approx Poly)영상이나 이미지의 윤곽점을 압축해 다각형으로 근사하기 위해 사용합니다.영상이나 이미지에서 윤곽선의 근사 다각형을 검출할 수 있습니다.메인 코드import cv2src = cv2.imread(\"Image/21.png\", cv2.IMREAD_COLOR)gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)binary = cv2.bitwise_not(binary)contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_TC89_KCOS)for contour in contours: epsilon = cv2.arcLength(contour, True) * 0.02 approx_poly = cv2.approxPolyDP(contour, epsilon, True) for approx in approx_poly: cv2.circle(src, tuple(approx[0]), 3, (255, 0, 0), -1)cv2.imshow(\"src\", src)cv2.waitKey(0)cv2.destroyAllWindows()세부 코드for contour in contours: epsilon = cv2.arcLength(contour, True) * 0.02반복문을 사용하여 색인값과 하위 윤곽선 정보로 반복합니다.근사치 정확도를 계산하기 위해 윤곽선 전체 길이의 2%로 활용합니다윤곽선의 전체 길이를 계산하기 위해 cv2.arcLength()을 이용해 검출된 윤곽선의 전체 길이를 계산합니다.cv2.arcLength(윤곽선, 폐곡선)을 의미합니다.윤곽선은 검출된 윤곽선들이 저장된 Numpy 배열입니다.폐곡선은 검출된 윤곽선이 닫혀있는지, 열려있는지 설정합니다. Tip : 폐곡선을 True로 사용할 경우, 윤곽선이 닫혀 최종 길이가 더 길어집니다. (끝점 연결 여부를 의미)approx_poly = cv2.approxPolyDP(contour, epsilon, True)cv2.approxPolyDP()를 활용해 윤곽선들의 윤곽점들로 근사해 근사 다각형으로 반환합니다.cv2.approxPolyDP(윤곽선, 근사치 정확도, 폐곡선)을 의미합니다.윤곽선은 검출된 윤곽선들이 저장된 Numpy 배열입니다.근사치 정확도는 입력된 다각형(윤곽선)과 반환될 근사화된 다각형 사이의 최대 편차 간격을 의미합니다.폐곡선은 검출된 윤곽선이 닫혀있는지, 열려있는지 설정합니다. Tip : 근사치 정확도의 값이 낮을 수록, 근사를 더 적게해 원본 윤곽과 유사해집니다.for approx in approx_poly: cv2.circle(src, tuple(approx[0]), 3, (255, 0, 0), -1)다시 반복문을 통해 근사 다각형을 반복해 근사점을 이미지 위해 표시합니다.근사 다각형의 정보는 윤곽선의 배열 형태와 동일합니다.추가 정보다각형 근사는 더글라스-패커(Douglas-Peucker) 알고리즘을 사용합니다.반복과 끝점을 이용해 선분으로 구성된 윤곽선들을 더 적은 수의 윤곽점으로 동일하거나 비슷한 윤곽선으로 데시메이트(decimate)합니다.더글라스-패커 알고리즘은 근사치 정확도(epsilon)의 값으로 기존의 다각형과 윤곽점이 압축된 다각형의 최대 편차를 고려해 다각형을 근사하게 됩니다. Tip : 데시메이트란 일정 간격으로 샘플링된 데이터를 기존 간격보다 더 큰 샘플링 간격으로 다시 샘플링하는 것을 의미합니다.출력 결과" }, { "title": "OpenCV - 21. 윤곽선 검출", "url": "/posts/opencv-21/", "categories": "OpenCV", "tags": "OpenCV, Contour Detection", "date": "2022-04-15 00:12:00 +0900", "snippet": "윤곽선(Contour)영상이나 이미지의 윤곽선(컨투어)을 검출하기 위해 사용합니다.영상이나 이미지에서 외곽과 내곽의 윤곽선(컨투어)을 검출할 수 있습니다.메인 코드import cv2src = cv2.imread(\"Image/20.png\", cv2.IMREAD_COLOR)gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)binary = cv2.bitwise_not(binary)contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)for i in range(len(contours)): cv2.drawContours(src, [contours[i]], 0, (0, 0, 255), 2) cv2.putText(src, str(i), tuple(contours[i][0][0]), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 1) print(i, hierarchy[0][i]) cv2.imshow(\"src\", src) cv2.waitKey(0)cv2.destroyAllWindows()세부 코드gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)binary = cv2.bitwise_not(binary)윤곽선(컨투어)를 검출하는 주된 요소는 하얀색의 객체를 검출합니다.그러므로 배경은 검은색이며 검출하려는 물체는 하얀색의 성질을 띄게끔 변형합니다.이진화 처리 후, 반전시켜 검출하려는 물체를 하얀색의 성질을 띄도록 변환합니다.contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)cv2.findContours()를 이용하여 이진화 이미지에서 윤곽선(컨투어)를 검색합니다.cv2.findContours(이진화 이미지, 검색 방법, 근사화 방법)을 의미합니다.반환값으로 윤곽선, 계층 구조를 반환합니다.윤곽선은 Numpy 구조의 배열로 검출된 윤곽선의 지점들이 담겨있습니다.계층 구조는 윤곽선의 계층 구조를 의미합니다. 각 윤곽선에 해당하는 속성 정보들이 담겨있습니다.for i in range(len(contours)): cv2.drawContours(src, [contours[i]], 0, (0, 0, 255), 2) cv2.putText(src, str(i), tuple(contours[i][0][0]), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 1) print(i, hierarchy[0][i]) cv2.imshow(\"src\", src) cv2.waitKey(0)반복문을 사용하여 검출된 윤곽선을 그리며 해당 윤곽선의 계층 구조를 표시합니다.cv2.drawContours()을 이용하여 검출된 윤곽선을 그립니다.cv2.drawContours(이미지, [윤곽선], 윤곽선 인덱스, (B, G, R), 두께, 선형 타입)을 의미합니다.윤곽선은 검출된 윤곽선들이 저장된 Numpy 배열입니다.윤곽선 인덱스는 검출된 윤곽선 배열에서 몇 번째 인덱스의 윤곽선을 그릴지를 의미합니다. Tip : 윤곽선 인덱스를 0으로 사용할 경우 0 번째 인덱스의 윤곽선을 그리게 됩니다. 하지만, 윤곽선 인수를 대괄호로 다시 묶을 경우, 0 번째 인덱스가 최댓값인 배열로 변경됩니다. Tip : 동일한 방식으로 [윤곽선], 0과 윤곽선, -1은 동일한 의미를 갖습니다. (-1은 윤곽선 배열 모두를 의미) 추가 정보검색 방법cv2.RETR_EXTERNAL : 외곽 윤곽선만 검출하며, 계층 구조를 구성하지 않습니다.cv2.RETR_LIST : 모든 윤곽선을 검출하며, 계층 구조를 구성하지 않습니다.cv2.RETR_CCOMP : 모든 윤곽선을 검출하며, 계층 구조는 2단계로 구성합니다.cv2.RETR_TREE : 모든 윤곽선을 검출하며, 계층 구조를 모두 형성합니다. (Tree 구조)근사화 방법cv2.CHAIN_APPROX_NONE : 윤곽점들의 모든 점을 반환합니다.cv2.CHAIN_APPROX_SIMPLE : 윤곽점들 단순화 수평, 수직 및 대각선 요소를 압축하고 끝점만 남겨 둡니다.cv2.CHAIN_APPROX_TC89_L1 : 프리먼 체인 코드에서의 윤곽선으로 적용합니다.cv2.CHAIN_APPROX_TC89_KCOS : 프리먼 체인 코드에서의 윤곽선으로 적용합니다.계층 구조계층 구조는 윤곽선을 포함 관계의 여부를 나타냅니다.즉, 외곽 윤곽선, 내곽 윤곽선, 같은 계층 구조를 구별할 수 있습니다.이 정보는 hierarchy에 담겨있습니다.hierarchy를 출력할 경우 다음과 같은 결과를 반환합니다.[[[ 2 -1 1 -1] [-1 -1 -1 0] [ 4 0 3 -1] [-1 -1 -1 2] [ 6 2 5 -1] [-1 -1 -1 4] [ 8 4 7 -1] [-1 -1 -1 6] [ 9 6 -1 -1] [10 8 -1 -1] [11 9 -1 -1] [-1 10 -1 -1]]]첫 번째 계층 구조는 [ 2 -1 1 -1]의 값을 갖습니다.[다음 윤곽선, 이전 윤곽선, 내곽 윤곽선, 외곽 윤곽선]에 대한 인덱스 정보를 포함하고 있습니다.인덱스 0의 윤곽선의 다음 윤곽선은 인덱스 2의 윤곽선을 의미하며 이전 윤곽선은 존재하지 않다는 것을 의미합니다.내곽 윤곽선은 인덱스 1에 해당하는 윤곽선을 자식 윤곽선으로 두고 있다는 의미입니다.즉, 인덱스 0 윤곽선 내부에 인덱스 1의 윤곽선이 포함되어 있습니다.외곽 윤곽선은 -1의 값을 갖고 있으므로 외곽 윤곽선은 존재하지 않습니다.다음 검출 결과를 통하여 쉽게 이해할 수 있습니다.0 [ 2 -1 1 -1]1 [-1 -1 -1 0]2 [ 4 0 3 -1]print(i, hierarchy[0][i])을 통하여 3개의 윤곽선을 출력한 결과입니다.다음 윤곽선과 이전 윤곽선의 정보가 -1의 값이 아니라면 서로 동등한 계층의 윤곽선입니다.0번 인덱스의 윤곽선과 동등한 계층에 있는 윤곽선은 2번 인덱스의 윤곽선입니다.0번 인덱스의 윤곽선은 1번 인덱스의 윤곽선을 내부 윤곽선으로 갖고 있습니다.1번 인덱스의 윤곽선은 동등한 계층에 있는 윤곽선이 없으므로 다음 윤곽선과 이전 윤곽선의 값이 -1입니다.1번 인덱스의 윤곽선은 내곽 윤곽선이 없으며, 외곽 윤곽선만 존재하여 0번 인덱스의 윤곽선을 외곽 윤곽선으로 반환합니다. Tip : 해당 예제는 cv2.RETR_CCOMP로 2 단계 계층 구조로만 표시합니다. Tip : 계층 구조를 사용하여 내곽, 외곽 윤곽선을 구분할 수 있습니다. 출력 결과0 [ 2 -1 1 -1]1 [-1 -1 -1 0]2 [ 4 0 3 -1]3 [-1 -1 -1 2]4 [ 6 2 5 -1]5 [-1 -1 -1 4]6 [ 8 4 7 -1]7 [-1 -1 -1 6]8 [ 9 6 -1 -1]9 [10 8 -1 -1]10 [11 9 -1 -1]11 [-1 10 -1 -1]" }, { "title": "OpenCV - 20. 캡쳐 및 녹화", "url": "/posts/opencv-20/", "categories": "OpenCV", "tags": "OpenCV, Capture, Record", "date": "2022-04-14 00:12:00 +0900", "snippet": "캡쳐 및 녹화(Capture &amp; Record)영상이나 이미지를 캡쳐하거나 녹화하기 위해 사용합니다. 영상이나 이미지를 연속적 또는 순간적으로 캡쳐하거나 녹화할 수 있습니다.메인 코드import datetimeimport cv2capture = cv2.VideoCapture(\"/Image/3.mp4\")fourcc = cv2.VideoWriter_fourcc(*'XVID')record = Falsewhile True: if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)): capture.open(\"/Image/3.mp4\") ret, frame = capture.read() cv2.imshow(\"VideoFrame\", frame) now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\") key = cv2.waitKey(33) if key == 27: break elif key == 26: print(\"캡쳐\") cv2.imwrite(\"D:/\" + str(now) + \".png\", frame) elif key == 24 print(\"녹화 시작\") record = True video = cv2.VideoWriter(\"D:/\" + str(now) + \".avi\", fourcc, 20.0, (frame.shape[1], frame.shape[0])) elif key == 3 print(\"녹화 중지\") record = False video.release() if record == True: print(\"녹화 중..\") video.write(frame)capture.release()cv2.destroyAllWindows()세부 코드fourcc = cv2.VideoWriter_fourcc(*'XVID')record = Falsefourcc를 생성하여 디지털 미디어 포맷 코드를 생성합니다. cv2.VideoWriter_fourcc(*'코덱')을 사용하여 인코딩 방식을 설정합니다.record 변수를 생성하여 녹화 유/무를 설정합니다. Tip : FourCC(Four Character Code) : 디지털 미디어 포맷 코드입니다. 즉, 코덱의 인코딩 방식을 의미합니다.import datetimenow = datetime.datetime.now().strftime(\"%d_%H-%M-%S\")datetime 모듈을 포함하여 현재 시간을 받아와 제목으로 사용합니다.now에 파일의 제목을 설정합니다. 날짜_시간-분-초의 형식으로 제목이 생성됩니다.key = cv2.waitKey(33)key 값에 현재 눌러진 키보드 키의 값이 저장됩니다. 33ms마다 갱신됩니다.if key == 27: breakelif key == 26: print(\"캡쳐\") cv2.imwrite(\"D:/\" + str(now) + \".png\", frame)elif key == 24 print(\"녹화 시작\") record = True video = cv2.VideoWriter(\"D:/\" + str(now) + \".avi\", fourcc, 20.0, (frame.shape[1], frame.shape[0]))elif key == 3 print(\"녹화 중지\") record = Falseif-elif`문을 이용하여 눌러진 키의 값을 판단합니다.27 = ESC, 26 = Ctrl + Z, 24 = Ctrl + X, 3 = Ctrl + C를 의미합니다.ESC키를 눌렀을 경우, 프로그램을 종료합니다.Ctrl + Z를 눌렀을 경우, 현재 화면을 캡쳐합니다. cv2.imwrite(\"경로 및 제목\", 이미지)를 이용하여 해당 이미지를 저장합니다.Ctrl + X를 눌렀을 경우, 녹화를 시작합니다. video에 녹화할 파일 형식을 설정합니다.cv2.VideoWriter(\"경로 및 제목\", 비디오 포맷 코드, FPS, (녹화 파일 너비, 녹화 파일 높이))를 의미합니다.Ctrl + C를 눌렀을 경우, 녹화를 중지합니다. video.release()를 사용하여 메모리를 해제합니다.녹화 시작할 때, record를 True로, 녹화를 중지할 때 record를 False로 변경합니다. Tip : key 값은 아스키 값을 사용합니다. Tip : FPS(Frame Per Second) : 영상이 바뀌는 속도를 의미합니다. 즉, 화면의 부드러움을 의미합니다. Tip : frame.shape는 (높이, 너비, 채널)의 값이 저장되어있습니다. if record == True: print(\"녹화 중..\") video.write(frame)if문을 이용하여 record가 True일때 video에 `프레임을 저장합니다.video.write(저장할 프레임)을 사용하여 프레임을 저장할 수 있습니다.추가 정보FourCC 종류CVID, Default, DIB, DIVX, H261, H263, H264, IV32, IV41, IV50, IYUB, MJPG, MP42, MP43, MPG4, MSVC, PIM1, Prompt, XVID Tip : 단일 채널 이미지의 경우, 사용할 수 없는 디지털 미디어 포맷 코드가 존재합니다." }, { "title": "OpenCV - 19. 기하학적 변환(Geometric Transformation)", "url": "/posts/opencv-19/", "categories": "OpenCV", "tags": "OpenCV, Geometric Transformation", "date": "2022-04-13 00:12:00 +0900", "snippet": "기하학적 변환(Geometric Perspective)기하학적 변환(Geometric Transform)이란 이미지를 인위적으로 확대, 축소, 위치 변경, 회전, 왜곡하는 등 이미지의 형태를 변환하는 것을 의미합니다.이미지를 구성하는 픽셀 좌푯값의 위치를 재배치하는 과정으로 볼 수 있습니다.기하학적 변환은 크게 아핀 변환(Affine Transformation)과 원근 변환(Perspective Transformation)이 있다.아핀 변환은 2×3 행렬을 사용하며 행렬 곱셈에 벡터 합을 활용해 표현할 수 있는 변환을 의미합니다.원근 변환은 3×3 행렬을 사용하며, 호모그래피(Homography)로 모델링할 수 있는 변환을 의미합니다. Tip : 아핀 변환은 정확하게는 3×3 행렬 형태를 갖습니다. 행렬의 세 번째 행이 [0, 1, 1] 값을 가져 OpenCV에서는 표현하지 않습니다.메인 코드import cv2import numpy as npsrc = cv2.imread(\"Image/18.jpg\", cv2.IMREAD_COLOR)height, width, channel = src.shapesrcPoint = np.array([[300, 200], [400, 200], [500, 500], [200, 500]], dtype=np.float32)dstPoint = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype=np.float32)matrix = cv2.getPerspectiveTransform(srcPoint, dstPoint)dst = cv2.warpPerspective(src, matrix, (width, height))cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()세부 코드srcPoint = np.array([[300, 200], [400, 200], [500, 500], [200, 500]], dtype=np.float32)dstPoint = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype=np.float32)원근 변환(Perspective Transformation)은 네 점을 사용하여 픽셀을 재매핑합니다.그러므로, 매핑에 사용할 변환 전 원본 이미지의 픽셀 좌표(srcPoint)과 변환 후 결과 이미지의 픽셀 좌표(dstPoint)를 선언합니다.변환 전 원본 이미지의 픽셀 좌표가 변환 후 결과 이미지의 픽셀로 매핑되어 이미지가 변형됩니다.예제의 좌표의 순서는 좌상, 우상, 우하, 좌하 순서입니다. numpy.array 형태로 선언하며, 좌표의 순서는 원본 순서와 결과 순서가 동일해야합니다.만약, 순서가 동일하지 않다면 비틀린(twist) 형태로 이미지가 표현될 수 있습니다. Tip : 픽셀 좌표 배열은 정밀도(dtype)를 float32 형식으로 선언해야 사용할 수 있습니다.matrix = cv2.getPerspectiveTransform(srcPoint, dstPoint)원근 맵 행렬 생성 함수(cv2.GetPerspectiveTransform)로 매핑 좌표에 대한 원근 맵 행렬을 생성할 수 있습니다.M = cv2.GetPerspectiveTransform(src, dst)는 변환 전 네 개의 픽셀 좌표(src)과 변환 후 네 개의 픽셀 좌표(dst)을 기반으로 원근 맵 행렬(M)을 생성합니다.만약, 예제와 같은 데이터로 원근 맵 행렬을 생성한다면 다음과 같은 행렬이 생성됩니다.[[-2.88000000e+01 -9.60000000e+00 1.05600000e+04] [-4.44089210e-15 -2.15400000e+01 4.30800000e+03] [-1.77809156e-17 -2.00000000e-02 1.00000000e+00]]dst = cv2.warpPerspective(src, matrix, (width, height))원근 변환 함수(cv2.warpPerspective)로 원근 맵 행렬에 대한 기하학적 변환을 수행할 수 있습니다.dst = cv2.warpPerspective(src, M, dsize, dst, flags, borderMode, borderValue)는 입력 이미지(src)에 원근 맵 행렬(M)을 적용하고, 출력 이미지 크기(dsize)로 변형해서 출력 이미지(dst)를 반환합니다.이미지를 변형하기 때문에 보간법(flags)과 테두리 외삽법(borderMode), 테두리 색상(borderValue)을 적용할 수 있습니다.출력 결과" }, { "title": "OpenCV - 18. 도형 그리기(Drawing)", "url": "/posts/opencv-18/", "categories": "OpenCV", "tags": "OpenCV, Drawing", "date": "2022-04-12 00:12:00 +0900", "snippet": "도형 그리기(Drawing)도형 그리기(Drawing)는 영상이나 이미지 위에 그래픽을 그려 검출 결과를 시각적으로 표시합니다.또한, 이미지 위에 검출 결과를 새롭게 그려 결괏값을 변형하거나 보정하기 위해서도 사용합니다도형 그리기는 직선, 사각형, 원, 다각형 등을 그릴 수 있습니다.도형 그리기는 선형 타입(Line Types), 비트 시프트(Bit Shift)에 따라 결과가 달라질 수 있습니다.선형 타입(Line Types)선형 타입은 도형을 그릴 때 어떤 유형의 선으로 그릴지 결정합니다.선형 타입으로는 브레젠험 알고리즘(Bresenham's algorithm), 안티 에일리어싱(Anti-Aliasing) 방식이 있습니다.선은 점들의 연속으로 이뤄진 형태로 두 점 사이의 직선을 그린다면 시작점과 도착점 사이에 연속한 점을 두게 되어 직선을 그리게 됩니다.일반적으로 직선의 방정식을 사용한다면 두 점 사이에 있는 모든 좌표를 알 수 있습니다.하지만 이 방식은 실수 형태로 소수점이 발생합니다.이미지는 래스터 형식의 사각형 격자 구조로 이뤄진 행렬이며, 점의 좌표는 모두 정수의 값으로 이뤄져 있습니다.브레젠험 알고리즘은 실수 연산을 하지 않고 정수 연산으로만 선을 그릴 수 있도록 개발된 알고리즘입니다.브레젠험 알고리즘은 4 연결 방식과 8 연결 방식이 있습니다.4 연결 방식의 경우 선분에 픽셀을 할당할 때 다음에 할당될 위치로 오른쪽, 왼쪽, 위쪽, 아래쪽 영역만 고려합니다.8 연결 방식의 경우 대각선 방향까지 추가돼 총 여덟 개의 위치를 고려합니다.안티 에일리어싱은 영상 신호의 결함을 없애기 위한 기법으로서 이미지나 객체의 가장자리 부분에서 발생하는 계단 현상을 없애고 계단을 부드럽게 보이도록 하는 방식입니다.안티 에일리어싱 방식은 가우스 필터링을 사용하며, 넓은 선의 경우 항상 끝이 둥글게 그려집니다.비트 시프트(Bit Shift)도형 그리기 함수에서 사용되는 값은 일반적으로 정숫값입니다.하지만 비트 시프트를 활용하면 소수점 이하의 값이 포함된 실숫값 좌표로도 도형 그리기 함수를 사용할 수 있습니다.비트 시프트는 서브 픽셀(sub pixel) 정렬을 지원해서 소수점 이하 자릿수를 표현할 수 있습니다.소수점은 도형 그리기 함수에서 표현할 수 없으므로 비트 시프트의 값으로 지정합니다.메인 코드import cv2import numpy as npsrc = np.zeros((768, 1366, 3), dtype=np.uint8)src = cv2.line(src, (100, 100), (1200, 100), (0, 0, 255), 3, cv2.LINE_AA)src = cv2.circle(src, (300, 300), 50, (0, 255, 0), cv2.FILLED, cv2.LINE_4)src = cv2.rectangle(src, (500, 200), (1000, 400), (255, 0, 0), 5, cv2.LINE_8)src = cv2.ellipse(src, (1200, 300), (100, 50), 0, 90, 180, (255, 255, 0), 2)pts1 = np.array([[100, 500], [300, 500], [200, 600]])pts2 = np.array([[600, 500], [800, 500], [700, 600]])src = cv2.polylines(src, [pts1], True, (0, 255, 255), 2)src = cv2.fillPoly(src, [pts2], (255, 0, 255), cv2.LINE_AA)src = cv2.putText(src, \"YUNDAEHEE\", (900, 600), cv2.FONT_HERSHEY_COMPLEX, 2, (255, 255, 255), 3)cv2.imshow(\"src\", src)cv2.waitKey()cv2.destroyAllWindows()세부 코드src = cv2.line(src, (100, 100), (1200, 100), (0, 0, 255), 3, cv2.LINE_AA)직선 그리기 함수(cv2.line)로 입력 이미지에 직선을 그릴 수 있습니다.dst = cv2.line(src, pt1, pt2, color, thickness, lineType, shift)는 입력 이미지(src)에 시작 좌표(pt1)부터 도착 좌표(pt2)를 지나는 특정 색상(color)과 두께(thickness)의 직선을 그립니다. 추가로 선형 타입(lineType), 비트 시프트(shift)를 설정할 수 있습니다.설정된 입력값으로 그려진 직선이 포함된 출력 이미지(dst)을 생성합니다.src = cv2.circle(src, (300, 300), 50, (0, 255, 0), cv2.FILLED, cv2.LINE_4)원 그리기 함수(cv2.circle)로 입력 이미지에 원을 그릴 수 있습니다.dst = cv2.circle(src, center, radius, color, thickness, lineType, shift)는 입력 이미지(src)에 중심점(center)으로부터 반지름(radius)크기의 특정 색상(color)과 두께(thickness)의 원을 그립니다. 추가로 선형 타입(lineType), 비트 시프트(shift)를 설정할 수 있습니다.만약, 내부가 채워진 원을 그리는 경우, 두께에 cv2.FILLED을 사용해 내부를 채울 수 있습니다.설정된 입력값으로 그려진 원이 포함된 출력 이미지(dst)을 생성합니다.src = cv2.rectangle(src, (500, 200), (1000, 400), (255, 0, 0), 5, cv2.LINE_8)사각형 그리기 함수(cv2.rectangle)로 입력 이미지에 원을 그릴 수 있습니다.dst = cv2.rectangle(src, pt1, pt2, color, thickness, lineType, shift)는 입력 이미지(src)에 좌측 상단 모서리 좌표(pt1)부터 우측 하단 모서리 좌표(pt2)로 구성된 특정 색상(color)과 두께(thickness)의 사각형을 그립니다. 추가로 선형 타입(lineType), 비트 시프트(shift)를 설정할 수 있습니다.설정된 입력값으로 그려진 사각형이 포함된 출력 이미지(dst)을 생성합니다.src = cv2.ellipse(src, (1200, 300), (100, 50), 0, 90, 180, (255, 255, 0), 2)호 그리기 함수(cv2.ellipse)로 입력 이미지에 원을 그릴 수 있습니다.dst = cv2.ellipse(src, center, axes, angle, startAngle, endAngle, color, thickness, lineType, shift)는 입력 이미지(src)에 중심점(center)으로부터 장축과 단축(axes) 크기를 갖는 특정 색상(color)과 두께(thickness)의 호를 그립니다.각도(angle)는 장축이 기울어진 각도를 의미하며, 시작 각도(startAngle)와 도착 각도(endAngle)를 설정해 호의 형태를 구성합니다. 추가로 선형 타입(lineType), 비트 시프트(shift)를 설정할 수 있습니다.설정된 입력값으로 그려진 호가 포함된 출력 이미지(dst)을 생성합니다.pts1 = np.array([[100, 500], [300, 500], [200, 600]])pts2 = np.array([[600, 500], [800, 500], [700, 600]])poly 함수를 사용하는 경우, numpy 형태로 저장된 위치 좌표들이 필요합니다.n개의 점이 저장된 경우, n 각형을 그릴 수 있습니다.src = cv2.polylines(src, [pts1], True, (0, 255, 255), 2)내부가 채워지지 않은 다각형 그리기 함수(cv2.polylines)로 입력 이미지에 다각형을 그릴 수 있습니다.dst = cv2.ellipse(src, pts, isClosed, color, thickness, lineType, shift)는 입력 이미지(src)에 선들의 묶음(pts) 이뤄진 N개의 내부가 채워지지 않은 다각형을 그립니다.닫힘 여부(isClosed)를 설정해 처음 좌표와 마지막 좌표의 연결 여부를 설정하며, 설정한 색상(color)과 두께(thickness)의 다각형이 그려집니다.추가로 선형 타입(lineType), 비트 시프트(shift)를 설정할 수 있습니다.설정된 입력값으로 그려진 다각형이 포함된 출력 이미지(dst)을 생성합니다.src = cv2.fillPoly(src, [pts2], (255, 0, 255), cv2.LINE_AA)내부가 채워진 다각형 그리기 함수(cv2.fillPoly)로 입력 이미지에 다각형을 그릴 수 있습니다.dst = cv2.ellipse(src, pts, color, thickness, lineType, shift, offset)는 입력 이미지(src)에 선들의 묶음(pts) 이뤄진 N개의 내부가 채워지지 않은 다각형을 그립니다.설정한 색상(color)과 두께(thickness)의 다각형이 그려집니다.추가로 선형 타입(lineType), 비트 시프트(shift), 오프셋(offset)을 설정할 수 있습니다.오프셋은 좌표를 (x, y)만큼 이동시켜 표시할 수 있습니다.설정된 입력값으로 그려진 다각형이 포함된 출력 이미지(dst)을 생성합니다.src = cv2.putText(src, \"YUNDAEHEE\", (900, 600), cv2.FONT_HERSHEY_COMPLEX, 2, (255, 255, 255), 3)문자 그리기 함수(cv2.putText)로 입력 이미지에 문자를 그릴 수 있습니다.dst = cv2.putText(src, text, org, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)는 입력 이미지(src)에 문자열(text)을 텍스트 박스의 좌측 상단 모서리(org)를 기준으로 문자가 그려집니다.설정한 글꼴(fontFace)과 글자 크기(fontScale), 색상(color)과 두께(thickness)의 다각형이 그려집니다.추가로 선형 타입(lineType), 기준 좌표(bottomLeftOrigin)를 설정할 수 있습니다.기준 좌표는 텍스트 박스 좌측 상단 모서리가 아닌 텍스트 박스 좌측 하단 모서리를 사용할 경우 기준 좌표에 true를 지정합니다.설정된 입력값으로 그려진 문자가 포함된 출력 이미지(dst)을 생성합니다.추가 정보선형 타입 종류 속성 의미 cv2.FILLED 내부 채우기 cv2.LINE_4 4점 이웃 연결 cv2.LINE_8 8점 이웃 연결 cv2.LINE_AA AntiAlias 글꼴 종류 속성 의미 비고 cv2.FONT_HERSHEY_SIMPLEX 보통 크기의 산세리프 글꼴 - cv2.FONT_HERSHEY_PLAIN 작은 크기의 산세리프 글꼴 - cv2.FONT_HERSHEY_DUPLEX 보통 크기의 산세리프 글꼴 정교함 cv2.FONT_HERSHEY_COMPLEX 보통 크기의 세리프 글꼴 - cv2.FONT_HERSHEY_TRIPLEX 보통 크기의 세리프 글꼴 정교함 cv2.FONT_HERSHEY_COMPLEX_SMALL 작은 크기의 손글씨 글꼴 - cv2.FONT_HERSHEY_SCRIPT_SIMPLEX 보통 크기의 손글씨 글꼴 - cv2.FONT_HERSHEY_SCRIPT_COMPLEX 보통 크기의 손글씨 글꼴 정교함 cv2.FONT_ITALIC 기울임 꼴 - 출력 결과" }, { "title": "OpenCV - 17. 채널 분리 및 병합(Channel Split & Merge)", "url": "/posts/opencv-17/", "categories": "OpenCV", "tags": "OpenCV, Split, Merge", "date": "2022-04-11 00:12:00 +0900", "snippet": "채널 분리(Split) 및 병합(Merge)채널 분리(Split)과 병합(Merge)은 영상이나 이미지의 색상 공간의 채널을 분리하거나 합치기 위해 사용합니다.예를 들어, BGR 색상 공간을 B(Blue), G(Green), R(Red)로 분리해 단일 채널을 가진 배열로 반환할 수 있습니다.분리된 채널의 값을 변경하거나 순서를 변경해, GB(R/2) 공간을 만들거나 새로운 색상 공간으로 변경할 수도 있습니다. Tip : OpenCV의 가산 혼합의 삼원색 기본 배열순서는 BGR입니다.메인 코드import cv2src = cv2.imread(\"Image/16.jpg\", cv2.IMREAD_COLOR)b, g, r = cv2.split(src)inverse = cv2.merge((r, g, b))cv2.imshow(\"b\", b)cv2.imshow(\"g\", g)cv2.imshow(\"r\", r)cv2.imshow(\"inverse\", inverse)cv2.waitKey()cv2.destroyAllWindows()세부 코드b, g, r = cv2.split(src)채널 분리 함수(cv2.split)로 이미지에서 채널을 분리할 수 있습니다.mv = cv2.split(src)는 입력 이미지(src)에서 채널을 분리해 단일 채널 이미지 배열(mv)을 생성합니다.mv는 목록(list) 형식으로 반환되며, b, g, r 등으로 형태로 각 목록의 원솟값을 변수로 지정할 수 있습니다.분리된 채널의 순서에 맞게 각 변수에 할당됩니다. Tip : 분리된 채널들은 단일 채널이므로 흑백 색상으로 표현됩니다.inverse = cv2.merge((r, g, b))채널 병합 함수(cv2.merge)로 분리된 채널을 병합해 하나의 이미지로 합칠 수 있습니다.dst = cv2.merge(mv)로 단일 채널 이미지 배열(mv)를 병합해 출력 이미지(dst)를 생성합니다.채널을 변형한 뒤에 다시 합치거나 순서를 변경해 병합할 수 있습니다.순서가 변경될 경우, 원본 이미지와 다른 색상으로 표현될 수 있습니다.추가 정보numpy 형식 채널 분리b = src[:, :, 0]g = src[:, :, 1]r = src[:, :, 2]이미지[높이, 너비, 채널]을 이용하여 특정 영역의 특정 채널만 불러올 수 있습니다.:, :, n을 입력할 경우, 이미지 높이와 너비를 그대로 반환하고 n번째 채널만 반환하여 적용합니다. Tip : src[..., n]의 형태로도 사용할 수 있습니다.빈 이미지height, width, channel = src.shapezero = np.zeros((height, width, 1), dtype=np.uint8)bgz = cv2.merge((b, g, zero))검은색 빈 공간 이미지가 필요할 때는 np.zeros((높이, 너비, 채널), dtype=정밀도)을 이용해 빈 이미지를 생성할 수 있습니다.Blue, Green, Zero 이미지를 병합할 경우, Red 채널 영역이 모두 흑백이미지로 변경됩니다. Tip : import numpy as np가 포함된 상태여야합니다. Tip : 특정 색상의 이미지를 생성하려는 경우에는 np.full((높이, 너비, 채널), (b, g, r), dtype=정밀도)을 이용해 특정 색상 이미지를 생성할 수 있습니다. 출력 결과BlueGreenRedInverseBlue, Green, Zero" }, { "title": "OpenCV - 16. 배열 병합(Array Merge)", "url": "/posts/opencv-16/", "categories": "OpenCV", "tags": "OpenCV, Array, Merge, addWeighted", "date": "2022-04-10 00:12:00 +0900", "snippet": "배열 병합(addWeighted)영상이나 이미지에서 색상을 검출 할 때, 배열 요소의 범위 설정 함수(cv2.inRange)의 영역이 한정되어 색상을 설정하는 부분이 제한되어 있습니다.예를 들어, 빨간색 영역을 검출하려 할 때, 빨간색 영역이 약 0 ~ 5와 약 170 ~ 179으로 범위가 두 가지로 나눠져 있습니다.이 문제를 해결하려면 배열 요소의 범위 설정 함수를 두 개의 범위로 설정하고 검출한 두 요소의 배열을 병합해서 하나의 공간으로 만들어야 합니다.이때 배열 병합 함수를 사용하며, 서로 다른 두 범위의 배열을 병합할 때 사용합니다.메인 코드import cv2src = cv2.imread(\"Image/14.jpg\", cv2.IMREAD_COLOR)hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)h, s, v = cv2.split(hsv)lower_red = cv2.inRange(hsv, (0, 100, 100), (5, 255, 255))upper_red = cv2.inRange(hsv, (170, 100, 100), (180, 255, 255))added_red = cv2.addWeighted(lower_red, 1.0, upper_red, 1.0, 0.0)red = cv2.bitwise_and(hsv, hsv, mask = added_red)red = cv2.cvtColor(red, cv2.COLOR_HSV2BGR)cv2.imshow(\"red\", red)cv2.waitKey()cv2.destroyAllWindows()세부 코드lower_red = cv2.inRange(hsv, (0, 100, 100), (5, 255, 255))upper_red = cv2.inRange(hsv, (170, 100, 100), (180, 255, 255))added_red = cv2.addWeighted(lower_red, 1.0, upper_red, 1.0, 0.0)빨간색 영역은 0 ~ 5, 170 ~ 179의 범위로 두 부분으로 나뉘어 있습니다.이때, 두 부분을 합쳐서 한 번에 출력하기 위해서 사용합니다.배열 요소의 범위 설정 함수(cv2.inRange)를 사용하여 빨간색 영역의 범위를 검출합니다.배열 요소 범위 설정 함수는 다채널 이미지도 한 번에 범위를 설정할 수 있습니다.색상을 분리한 두 배열을 배열 병합 함수(cv2.addWeighted)로 입력된 두 배열의 하나로 병합합니다.dst = cv2.addWeighted(src1, alpha, src2, beta, gamma, dtype = None)은 입력 이미지1(src1)에 대한 가중치1(alpha) 곱과 입력 이미지2(src2)에 대한 가중치2(beta) 곱의 합에 추가 합(gamma)을 더해서 계산합니다.정밀도(dtype)은 출력 이미지(dst)의 정밀도를 설정하며, 할당하지 않을 경우, 입력 이미지1과 같은 정밀도로 할당됩니다.두 이미지를 그대로 합칠 예정이므로, 가중치1과 가중치2의 값은 1.0으로 사용하고, 추가 합은 사용하지 않으므로 0.0을 할당합니다.배열 병합 함수는 다음과 같은 수식으로 나타낼 수 있습니다.\\[dst = src1 \\times alpha + src2 \\times beta + gamma\\] Tip : 배열 병합 함수는 알파 블렌딩(alpha blending)을 구현할 수 있어 서로 다른 이미지를 불투명하게 혼합해서 표시할 수 있습니다.출력 결과" }, { "title": "OpenCV - 15. Hue, Saturation, Value(HSV)", "url": "/posts/opencv-15/", "categories": "OpenCV", "tags": "OpenCV, Hue, Saturation, Value, HSV", "date": "2022-04-09 00:12:00 +0900", "snippet": "HSV(Hue, Saturation, Value)HSV(Hue, Saturation, Value) 공간은 색상을 표현하기에 간편한 색상 공간입니다.이미지에서 색상을 검출한다고 가정할 때 BGR이나 RGB 패턴으로는 인간이 인지하는 영역의 색상을 구별하기에는 매우 어렵고 복잡합니다.하지만 HSV 색상 공간을 활용한다면 간편하고 빠르게 특정 색상을 검출하고 분리할 수 있습니다.색상(Hue)은 빨간색, 노란색, 파란색 등으로 인식되는 색상 중 하나 또는 둘의 조합과 유사한 것처럼 보이는 시각적 감각의 속성을 의미합니다.0°에서 360°의 범위로 표현되며, 파란색은 220°에서 260° 사이에 있습니다. OpenCV에서는 0 ~ 179의 범위로 표현됩니다.채도(Saturation)는 이미지의 색상 깊이로, 색상이 얼마나 선명한(순수한) 색인지를 의미합니다.아무것도 섞지 않아 맑고 깨끗하며 원색에 가까운 것을 채도가 높다고 표현합니다.0%에서 100%의 비율로 표현되며, 0%에 가까울수록 무채색, 100%에 가까울수록 가장 선명한(순수한)색이 됩니다. OpenCV에서는 0 ~ 255의 범위로 표현됩니다.명도(Value)는 색의 밝고 어두운 정도를 의미합니다. 명도가 높을수록 색상이 밝아지며, 명도가 낮을수록 색상이 어두워집니다.0%에서 100%의 비율로 표현되며, 0%에 가까울수록 검은색, 100%에 가까울수록 가장 맑은색이 됩니다. OpenCV에서는 0 ~ 255의 범위로 표현됩니다. Tip : 0 ~ 360의 범위는 1 Byte(uint8)의 범위를 벗어나게 되므로 불필요한 메모리 사용을 줄이기 위해, 절반의 값인 0 ~ 179의 범위로 표현합니다.메인 코드 (1)import cv2src = cv2.imread(\"Image/14.jpg\", cv2.IMREAD_COLOR)hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)h, s, v = cv2.split(hsv)cv2.imshow(\"h\", h)cv2.imshow(\"s\", s)cv2.imshow(\"v\", v)cv2.waitKey()cv2.destroyAllWindows()세부 코드hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)h, s, v = cv2.split(hsv)색상 공간 변환 함수(cv2.cvtcolor)로 이미지의 색상 공간을 BGR에서 HSV로 변경합니다.각각의 채널로 분리하기 위해서 채널 분리 함수(cv2.split)를 적용합니다.mv = cv2.threshold(src)는 입력 이미지(src)의 채널을 분리하여 배열(mv)의 형태로 반환합니다. Tip : 분리된 채널들은 단일 채널이므로 흑백의 색상으로만 표현됩니다.출력 결과HueSaturationValue메인 코드 (2)import cv2src = cv2.imread(\"Image/tomato.jpg\", cv2.IMREAD_COLOR)hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)h, s, v = cv2.split(hsv)h = cv2.inRange(h, 8, 20)orange = cv2.bitwise_and(hsv, hsv, mask = h)orange = cv2.cvtColor(orange, cv2.COLOR_HSV2BGR)cv2.imshow(\"orange\", orange)cv2.waitKey()cv2.destroyAllWindows()세부 코드h = cv2.inRange(h, 8, 20)orange = cv2.bitwise_and(hsv, hsv, mask = h)orange = cv2.cvtColor(orange, cv2.COLOR_HSV2BGR)Hue의 범위를 조정하여 특정 색상의 범위만 출력할 수 있습니다.배열 요소의 범위 설정 함수(cv2.inRange)로 입력된 배열의 특정 범위 영역만 추출할 수 있습니다.dst = cv2.inRange(src, lowerb, upperb)는 입력 이미지(src)의 낮은 범위(lowerb)에서 높은 범위(upperb) 사이의 요소를 추출합니다.주황색은 약 8 ~ 20 범위를 갖습니다.이후, 해당 추출한 영역을 마스크로 사용해 이미지 위에 덧씌워 해당 부분만 출력합니다.비트 연산 AND(cv2.bitwise_and)로 간단하게 마스크를 덧씌울 수 있습니다.dst = cv2.bitwise_and(src1, src2, mask)는 입력 이미지1(src1)과 입력 이미지2(src2)의 픽셀의 이진값이 동일한 영역만 AND 연산하여 반환합니다.마스크 영역이 존재한다면 마스크 영역만 AND 연산을 진행합니다.특정 영역(마스크)의 AND 연산이 완료됐다면 다시 HSV 색상 공간에서 BGR 색상 공간으로 변경합니다.출력 결과" }, { "title": "OpenCV - 14. 가장자리 검출", "url": "/posts/opencv-14/", "categories": "OpenCV", "tags": "OpenCV, Edge, Canny, Sobel, Laplacian", "date": "2022-04-08 00:12:00 +0900", "snippet": "가장자리 검출(Edge)가장자리(Edge)는 가장 바깥 부분의 둘레를 의미하며, 객체의 테두리로 볼 수 있습니다.이미지 상에서 가장자리는 전경(Foreground)과 배경(Background)이 구분되는 지점이며, 전경과 배경 사이에서 밝기가 큰 폭으로 변하는 지점이 객체의 가장자리가 됩니다.그러므로 가장자리는 픽셀의 밝기가 급격하게 변하는 부분으로 간주할 수 있습니다.가장자리를 찾기 위해 미분(Derivative)과 기울기(Gradient) 연산을 수행하며, 이미지 상에서 픽셀의 밝기 변화율이 높은 경계선을 찾습니다.메인 코드import cv2src = cv2.imread(\"Image/13.jpg\", cv2.IMREAD_COLOR)gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)sobel = cv2.Sobel(gray, cv2.CV_8U, 1, 0, 3)laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)canny = cv2.Canny(src, 100, 255)cv2.imshow(\"sobel\", sobel)cv2.imshow(\"laplacian\", laplacian)cv2.imshow(\"canny\", canny)cv2.waitKey()cv2.destroyAllWindows()세부 코드 (Sobel)sobel = cv2.Sobel(gray, cv2.CV_8U, 1, 0, 3)소벨 함수(cv2.Sobel)로 입력 이미지에서 가장자리를 검출할 수 있습니다.미분 값을 구할 때 가장 많이 사용되는 연산자이며, 인접한 픽셀들의 차이로 기울기(Gradient)의 크기를 구합니다.이때 인접한 픽셀들의 기울기를 계산하기 위해 컨벌루션 연산을 수행합니다.dst = cv2.Sobel(src, ddepth, dx, dy, ksize, scale, delta, borderType)은 입력 이미지(src)에 출력 이미지 정밀도(ddepth)를 설정하고 dx(X 방향 미분 차수), dy(Y 방향 미분 차수), 커널 크기(ksize), 비율(scale), 오프셋(delta), 테두리 외삽법(borderType)을 설정하여 결과 이미지(dst)를 반환합니다.출력 이미지 정밀도는 반환되는 결과 이미지의 정밀도를 설정합니다.X 방향 미분 차수는 이미지에서 X 방향으로 미분할 차수를 설정합니다.Y 방향 미분 차수는 이미지에서 Y 방향으로 미분할 차수를 설정합니다.커널 크기는 소벨 마스크의 크기를 설정합니다. 1, 3, 5, 7 등의 홀수 값을 사용하며, 최대 31까지 설정할 수 있습니다.비율과 오프셋은 출력 이미지를 반환하기 전에 적용되며, 주로 시각적으로 확인하기 위해 사용합니다.픽셀 외삽법은 이미지 가장자리 부분의 처리 방식을 설정합니다. Tip : X 방향 미분 차수와 Y 방향 미분 차수는 합이 1 이상이여야 하며, 0의 값은 해당 방향으로 미분하지 않음을 의미합니다.세부 코드 (Laplacian)laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)라플라시안 함수(cv2.Laplacian)로 입력 이미지에서 가장자리를 검출할 수 있습니다.라플라시안은 2차 미분의 형태로 가장자리가 밝은 부분에서 발생한 것인지, 어두운 부분에서 발생한 것인지 알 수 있습니다.2차 미분 방식은 X 축과 Y 축을 따라 2차 미분한 합을 의미합니다.dst = cv2.laplacian(src, ddepth, ksize, scale, delta, borderType)은 입력 이미지(src)에 출력 이미지 정밀도(ddepth)를 설정하고 커널 크기(ksize), 비율(scale), 오프셋(delta), 테두리 외삽법(borderType)을 설정하여 결과 이미지(dst)를 반환합니다.출력 이미지 정밀도는 반환되는 결과 이미지의 정밀도를 설정합니다.커널 크기는 라플라시안 필터의 크기를 설정합니다. 커널의 값이 1일 경우, 중심값이 -4인 3 x 3 Aperture Size를 사용합니다.비율과 오프셋은 출력 이미지를 반환하기 전에 적용되며, 주로 시각적으로 확인하기 위해 사용합니다.픽셀 외삽법은 이미지 가장자리 부분의 처리 방식을 설정합니다.세부 코드 (Canny)canny = cv2.Canny(src, 100, 255)캐니 함수(cv2.Canny)로 입력 이미지에서 가장자리를 검출할 수 있습니다.캐니 엣지는 라플라스 필터 방식을 개선한 방식으로 x와 y에 대해 1차 미분을 계산한 다음, 네 방향으로 미분합니다.네 방향으로 미분한 결과로 극댓값을 갖는 지점들이 가장자리가 됩니다.앞서 설명한 가장자리 검출기보다 성능이 월등히 좋으며 노이즈에 민감하지 않아 강한 가장자리를 검출하는 데 목적을 둔 알고리즘입니다.dst = cv2.Canny(src, threshold1, threshold2, apertureSize, L2gradient)는 입력 이미지(src)를 하위 임곗값(threshold1), 상위 임곗값(threshold2), 소벨 연산자 마스크 크기(apertureSize), L2 그레이디언트(L2gradient)을 설정하여 결과 이미지(dst)를 반환합니다.하위 임곗값과 상위 임곗값으로 픽셀이 갖는 최솟값과 최댓값을 설정해 검출을 진행합니다.픽셀이 상위 임곗값보다 큰 기울기를 가지면 픽셀을 가장자리로 간주하고, 하위 임곗값보다 낮은 경우 가장자리로 고려하지 않습니다.소벨 연산자 마스크 크기는 소벨 연산을 활용하므로, 소벨 마스크의 크기를 설정합니다.L2 그레이디언트는 L2-norm으로 방향성 그레이디언트를 정확하게 계산할지, 정확성은 떨어지지만 속도가 더 빠른 L1-norm으로 계산할지를 선택합니다.L1그라디언트 : \\(L_{1} = \\left \\| \\frac{dI}{dx} \\right \\| + \\left \\| \\frac{dI}{dy} \\right \\|\\)L2그라디언트 : \\(\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\)추가 정보픽셀 외삽법 종류 속성 의미 cv2.BORDER_CONSTANT iiiiii | abcdefgh | iiiiiii cv2.BORDER_REPLICATE aaaaaa | abcdefgh | hhhhhhh cv2.BORDER_REFLECT fedcba | abcdefgh | hgfedcb cv2.BORDER_WRAP cdefgh | abcdefgh | abcdefg cv2.BORDER_REFLECT_101 gfedcb | abcdefgh | gfedcba cv2.BORDER_REFLECT101 gfedcb | abcdefgh | gfedcba cv2.BORDER_DEFAULT gfedcb | abcdefgh | gfedcba cv2.BORDER_TRANSPARENT uvwxyz | abcdefgh | ijklmno cv2.BORDER_ISOLATED 관심 영역 (ROI) 밖은 고려하지 않음 출력 결과SobelLaplacianCanny" }, { "title": "OpenCV - 13. 흐림(Blur) 효과", "url": "/posts/opencv-13/", "categories": "OpenCV", "tags": "OpenCV, Blur", "date": "2022-04-07 00:12:00 +0900", "snippet": "흐림 효과(Blur)흐림 효과(Blur)는 블러링(Blurring) 또는 스무딩(Smoothing)이라 불리며, 노이즈를 줄이거나 외부 영향을 최소화하는 데 사용됩니다.흐림 효과는 영상이나 이미지를 번지게 하며, 해당 픽셀의 주변 값들과 비교하고 계산해서 픽셀들의 색상을 재조정합니다.단순히 이미지를 흐리게 만드는 것뿐만 아니라 노이즈를 제거해서 연산 시 계산을 빠르고 정확하게 수행하는 데 도움을 줍니다.또한, 이미지의 해상도를 변경하는 경우에도 사용되는데 이미지의 크기를 변경하면 존재하지 않는 데이터를 생성하거나 존재하는 데이터를 줄여야 하므로 샘플링된 이미지를 재구성할 때 사용됩니다.메인 코드import cv2src = cv2.imread(\"Image/12.jpg\", cv2.IMREAD_COLOR)dst = cv2.blur(src, (9, 9), anchor=(-1, -1), borderType=cv2.BORDER_DEFAULT)cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()세부 코드dst = cv2.blur(src, (9, 9), anchor=(-1, -1), borderType=cv2.BORDER_DEFAULT)단순 흐림 효과 함수(cv2.blur)로 입력 이미지에 흐림 효과를 적용할 수 있습니다.단순 흐림 효과는 각 픽셀에 대해 커널을 적용해 모든 픽셀의 단순 평균을 구하는 연산입니다.dst = cv2.blur(src, ksize, anchor, borderType)는 입력 이미지(src)를 커널 크기(ksize), 고정점(anchor), 테두리 외삽법(borderType)으로 흐림 효과를 적용한 결과 이미지(dst)를 반환합니다.커널, 고정점, 테두리 외삽법에 대한 내용은 다음과 같습니다.커널(Kernel)커널(kernel)은 이미지에서 (x, y)의 픽셀과 해당 픽셀 주변을 포함한 작은 크기의 공간을 의미합니다.이 영역 각각의 특정한 수식이나 함수 등을 적용해 새로운 이미지를 얻는 알고리즘에서 사용됩니다.커널은 영역의 형태와 요소가 결합되는 방식을 정의하는 템플릿을 의미하기도 하며, 신호 처리 분야에서는 커널을 필터(filter)라고도 합니다.위 이미지의 파란색 사각형 내부가 커널이 되며, 파란색 사각형 크기가 3 x 3이므로, 커널의 크기는 3 x 3이 됩니다.고정점(Anchor Point)고정점(Anchor Point)은 커널을 통해 컨벌루션된 값을 할당한 지점입니다.여기서 컨벌루션(Convolution)이란 새로운 픽셀을 만들어 내기 위해 커널 크기의 화소 값을 이용해 어떤 시스템을 통과해 계산하는 것을 의미합니다.커널 내에서 고정점은 하나의 지점만을 가지며, 이미지와 어떻게 정렬되는지를 나타냅니다.위 이미지의 빨간색 부분이 고정점이 되며, 빨간색 사각형의 위치는 파란색 사각형을 기준으로 (1, 1)에 위치합니다.테두리 외삽법(Border Extrapolation)테두리 외삽법(Border Extrapolation)은 컨벌루션을 적용할 때, 이미지 가장자리 부분의 처리 방식을 의미합니다.컨벌루션을 적용하면 이미지 가장자리 부분은 계산이 불가능한 데, 이 문제를 해결하기 위해 테두리의 이미지 바깥쪽에 가상의 픽셀을 만들어 처리합니다.가상 픽셀의 값을 0으로 처리하거나, 임의의 값을 할당하거나, 커널이 연산할 수 있는 부분부터 연산을 수행하기도 합니다.예를 들어 cv2.BORDER_DEFAULT는 gfedcb | abcdefgh | gfedcba의 형태로 외삽을 진행하는데 abcdefgh는 픽셀의 값을 의미합니다.즉 테두리 부분이 a라면 테두리 밖의 부분은 이미지를 반사하듯이 표현되어, gfedcb나 gfedcba의 형태로 할당됩니다.위 이미지의 굵은 선 바깥 부분에 대해 테두리 외삽법이 적용됩니다.추가 정보픽셀 외삽법 종류 속성 의미 cv2.BORDER_CONSTANT iiiiii | abcdefgh | iiiiiii cv2.BORDER_REPLICATE aaaaaa | abcdefgh | hhhhhhh cv2.BORDER_REFLECT fedcba | abcdefgh | hgfedcb cv2.BORDER_WRAP cdefgh | abcdefgh | abcdefg cv2.BORDER_REFLECT_101 gfedcb | abcdefgh | gfedcba cv2.BORDER_REFLECT101 gfedcb | abcdefgh | gfedcba cv2.BORDER_DEFAULT gfedcb | abcdefgh | gfedcba cv2.BORDER_TRANSPARENT uvwxyz | abcdefgh | ijklmno cv2.BORDER_ISOLATED 관심 영역 (ROI) 밖은 고려하지 않음 출력 결과" }, { "title": "OpenCV - 12. 이진화(Binary)", "url": "/posts/opencv-12/", "categories": "OpenCV", "tags": "OpenCV, Binary", "date": "2022-04-06 00:12:00 +0900", "snippet": "이진화(Binary)이진화(Binary)는 어느 지점을 기준으로 값이 높거나 낮은 픽셀의 값을 대상으로 특정 연산을 수행할 때 사용합니다.일반적으로 값이 높거나 낮은 픽셀을 검은색 또는 흰색의 값으로 변경합니다.기준값에 따라 이분법적으로 구분해 픽셀을 참 또는 거짓으로 나누는 연산이며, 이미지 행렬에서 모든 픽셀에 대해 연산이 수행됩니다.메인 코드import cv2src = cv2.imread(\"Image/11.jpg\", cv2.IMREAD_COLOR)gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)ret, dst = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()세부 코드gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)ret, dst = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)이진화 함수(cv2.threshold)로 그레이스케일 이미지에 이진화를 적용할 수 있습니다.retval, dst = cv2.threshold(src, thresh, maxval, type)는 입력 이미지(src)를 임곗값 형식(type)에 따라 임곗값(thresh)과 최댓값(maxval)을 활용하여 설정 임곗값(retval)과 결과 이미지(dst)를 반환합니다.입력 이미지는 단일 채널 이미지(그레이스케일)을 입력해 사용합니다.임곗값 형식은 임곗값을 초과한 값은 최댓값으로 변경하고 임곗값 이하의 값은 0으로 바꾸는 등의 연산을 적용합니다.설정 임곗값은 일반적으로 임곗값과 동일하지만, 임곗값을 대신 계산해주는 알고리즘인 Otsu나 Triangle를 사용한다면, 해당 알고리즘에서 계산해준 임곗값을 알 수 있습니다.예제에서는 임곗값을 100, 최댓값을 255, 임곗값 형식을 cv2.THRESH_BINARY로 사용하였으므로, 픽셀의 값이 100을 초과하는 경우에는 255의 값으로 변경되며, 100 이하의 값은 0으로 변경됩니다.수식으로 표현한다면 \\(dst = (\\ src\\ &gt;\\ thresh\\ )\\ ?\\ maxval : 0\\) 으로 표현할 수 있습니다. Tip : 다중 채널 이미지를 입력 이미지로 사용하였을 때, 각 채널마다 이미지를 분리해 이진화 연산을 적용합니다.추가 정보임계값 형식 속성 의미 cv2.THRESH_BINARY dst = (src &gt; thresh) ? maxval : 0(임곗값을 초과할 경우 maxval, 아닐 경우 0) cv2.THRESH_BINARY_INV dst = (src &gt; thresh) ? 0 : maxval(임곗값을 초과할 경우 0, 아닐 경우 maxval) cv2.THRESH_TRUNC dst = (src &gt; thresh) ? thresh : src(임곗값을 초과할 경우 thresh, 아닐 경우 변형 없음) cv2.THRESH_TOZERO dst = (src &gt; thresh) ? src : 0(임곗값을 초과할 경우 변형 없음, 아닐 경우 0) cv2.THRESH_TOZERO_INV dst = (src &gt; thresh) ? 0 : src(임곗값을 초과할 경우 0, 아닐 경우 변형 없음) cv2.THRESH_MASK 검은색 이미지로 변경(마스크용) cv2.THRESH_OTSU 오츠 알고리즘 적용(단일 채널 이미지에만 적용 가능) cv2.THRESH_TRIANGLE 삼각형(Triangle) 알고리즘 적용(단일 채널 이미지에만 적용 가능) 출력 결과" }, { "title": "OpenCV - 11. 역상(Reverse Image)", "url": "/posts/opencv-11/", "categories": "OpenCV", "tags": "OpenCV, Reverse Image, Bitwise", "date": "2022-04-05 00:12:00 +0900", "snippet": "역상(Reverse Image)역상(Reverse Image)은 영상이나 이미지를 반전 된 색상으로 변환하기 위해서 사용합니다.픽셀 단위마다 비트 연산(Bitwise Operation)을 적용하는데, 그중 NOT 연산을 적용합니다.NOT 연산은 각 자릿수의 값을 반대로 바꾸는 연산입니다.만약 153의 값을 갖는 픽셀에 NOT 연산을 적용한다면 102의 값으로 변경됩니다.153은 0b10011001의 값을 가지며, 102는 0b01100110의 값을 갖습니다.즉, 10 진수의 픽셀값을 2 진수의 값으로 변경한 다음, 각 자릿수의 값을 반대로 바꾸게 됩니다.1은 0이 되며, 0은 1로 변경됩니다.메인 코드import cv2src = cv2.imread(\"Image/10.jpg\", cv2.IMREAD_COLOR)dst = cv2.bitwise_not(src)cv2.imshow(\"src\", src)cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()세부 코드dst = cv2.bitwise_not(src)NOT 연산 함수(cv2.bitwise_not)로 이미지에 NOT 연산을 적용할 수 있습니다.dst = cv2.bitwise_not(src, mask)는 입력 이미지(src), 마스크(mask)로 출력 이미지(dst)을 생성합니다.마스크는 NOT 연산을 적용할 특정 영역을 의미합니다. 마스크 배열이 포함되어 있다면, 해당 영역만 반전 연산을 적용합니다. Tip : not 연산 이외에도 and, or, xor 연산이 존재합니다.출력 결과" }, { "title": "OpenCV - 10. 색상 공간 변환(Convert Color)", "url": "/posts/opencv-10/", "categories": "OpenCV", "tags": "OpenCV, Convert Color", "date": "2022-04-04 00:12:00 +0900", "snippet": "색상 공간 변환(Convert Color)색상 공간 변환(Convert Color)은 본래의 색상 공간에서 다른 색상 공간으로 변환할 때 사용합니다.색상 공간 변환 함수는 데이터 타입을 같게 유지하고 채널을 변환합니다.입력된 이미지는 8 비트, 16 비트, 32 비트의 정밀도를 갖는 배열을 사용할 수 있습니다.출력된 이미지는 입력된 이미지의 이미지 크기와 정밀도가 동일한 배열이 됩니다.채널의 수가 감소하게 되어 이미지 내부의 데이터는 설정한 색상 공간과 일치하는 값으로 변환되며, 데이터 값이 변경되거나 채널 순서가 변경될 수 있습니다.메인 코드import cv2src = cv2.imread(\"Image/9.jpg\", cv2.IMREAD_COLOR)dst = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)cv2.imshow(\"src\", src)cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()세부 코드dst = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)색상 공간 변환 함수(cv2.cvtcolor)로 이미지의 색상 공간을 변경할 수 있습니다.dst = cv2.cvtcolor(src, code, dstCn)는 입력 이미지(src), 색상 변환 코드(code), 출력 채널(dstCn)으로 출력 이미지(dst)을 생성합니다.색상 변환 코드는 원본 이미지 색상 공간2결과 이미지 색상 공간을 의미합니다.원본 이미지 색상 공간은 원본 이미지와 일치해야합니다.출력 채널은 출력 이미지에 필요한 채널의 수를 설정합니다. Tip : BGR은 RGB 색상 채널을 의미합니다. (Byte 역순) Tip : 출력 채널은 기본값을 사용하여 자동으로 채널의 수를 결정하게 합니다.추가 정보채널 범위 형식 범위 CV_8U 0 ~ 255 CV_16U 0 ~ 65535 CV_32F 0 ~ 1 색상 공간 코드 속성 의미 비고 BGR Blue, Green, Red 채널 - BGRA Blue, Green, Red, Alpha 채널 - RGB Red, Green, Blue 채널 - RGBA Red, Green, Blue, Alpha 채널 - GRAY 단일 채널 그레이스케일 BGR565 Blue, Green, Red 채널 16 비트 이미지 XYZ X, Y, Z 채널 CIE 1931 색 공간 YCrCb Y, Cr, Cb 채널 YCC (크로마) HSV Hue, Saturation, Value 채널 색상, 채도, 명도 Lab L, a, b 채널 반사율, 색도1, 색도2 Luv L, u, v 채널 CIE Luv HLS Hue, Lightness, Saturation 채널 색상, 밝기, 채도 YUV Y, U, V 채널 밝기, 색상1, 색상2 BG, GB, RG 디모자이킹 단일 색상 공간으로 변경 _EA 디모자이킹 가장자리 인식 _VNG 디모자이킹 그라데이션 사용 원본 이미지 색상 공간2결과 이미지 색상 공간에 색상 공간 코드를 조합하여 사용할 수 있습니다.예) BGR2GRAY는 Blue, Green, Red 채널 이미지를 단일 채널, 그레이스케일 이미지로 변경합니다.출력 결과" }, { "title": "OpenCV - 09. Slice", "url": "/posts/opencv-9/", "categories": "OpenCV", "tags": "OpenCV, Slice", "date": "2022-04-03 00:12:00 +0900", "snippet": "자르기(Slice)자르기(Slice)는 영상이나 이미지에서 특정 영역을 잘라내는 연산을 의미하니다.특정 영역을 잘라내는 것을 관심 영역(Region Of Interest, ROI)이라 하며, 이미지 상에서 관심 있는 영역을 의미합니다.이미지를 처리할 때 객체를 탐지하거나 검출하는 영역을 명확하게 관심 영역이라 볼 수 있습니다.관심 영역에만 알고리즘을 적용한다면, 불필요한 연산이 줄어들고 정확도가 늘어나는 효과를 얻을 수 있습니다.메인 코드 (1)import cv2src = cv2.imread(\"image/8.jpg\", cv2.IMREAD_COLOR)dst = src[100:600, 200:700].copy()cv2.imshow(\"src\", src)cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()세부 코드dst = src[100:600, 200:700].copy()OpenCV의 이미지는 이미지는 numpy 배열 형식과 동일합니다.src 이미지에 src[높이(행), 너비(열)]로 관심 영역을 설정합니다.리스트(List)나 배열(Array)의 특정 영역을 자르는 방식과 동일합니다.이미지를 자르거나 복사할 때, dst = src의 형태로 사용할 경우, 얕은 복사(shallow copy)가 되어 원본도 영향을 받게 됩니다.그러므로, *.copy()를 이용해 깊은 복사(deep copy)를 진행합니다.메인 코드 (2)import cv2src = cv2.imread(\"Image/8.jpg\", cv2.IMREAD_COLOR)dst = src.copy() roi = src[100:600, 200:700]dst[0:500, 0:500] = roicv2.imshow(\"src\", src)cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()세부 코드dst = src.copy() dst 이미지를 생성할 때, dst = src.copy()가 아닌 dst = src로 적용한다면 깊은 복사가 적용되지 않습니다.얕은 복사로 이미지를 복사할 경우, dst 이미지와 src 이미지는 동일한 결과로 반환됩니다.roi = src[100:600, 200:700]dst[0:500, 0:500] = roiroi 이미지를 생성하여 src[높이(행), 너비(열)]로 관심 영역을 설정합니다.이후, dst[높이(행), 너비(열)] = roi를 이용하여 dst 이미지에 해당 영역을 붙여넣을 수 있습니다.잘라낸 이미지와 붙여넣을 이미지의 크기가 다르다면 이미지를 붙여넣을 수 없습니다.출력 결과" }, { "title": "OpenCV - 08. Image Resize", "url": "/posts/opencv-8/", "categories": "OpenCV", "tags": "OpenCV, Resize", "date": "2022-04-02 00:12:00 +0900", "snippet": "크기 조절(Resize)영상이나 이미지의 이미지를 확대하거나 축소하는 연산에서 확인할 수 있듯이 이미지의 크기를 변형하는 것은 단순한 연산이 아닙니다.이미지를 확대하는 경우에는 픽셀에 대한 보간법, 이미지를 축소하는 경우에는 픽셀에 대한 병합법이 수행됩니다.이미지 피라미드는 2배로 확대하거나 축소하는 경우만 가능하므로, 원하는 크기로 변환하기 위해서 이미지 크기 조절 함수를 사용합니다.이미지 크기를 조절하는 방법은 크게 두 가지 방법이 있습니다.첫 번째 방법은 이미지의 크기를 사용자가 요구하는 절대 크기로 변경하는 방법입니다. 즉, 임의의 크기(640×480이나 123×456 등의 이미지 크기)로 변환하는 것을 의미합니다.두 번째 방법은 이미지의 크기를 비율에 맞게 상대 크기로 변경하는 방법입니다. 이 경우, 입력 이미지의 크기와 비례하도록 너비와 높이가 계산됩니다.메인 코드import cv2src = cv2.imread(\"Image/7.jpg\", cv2.IMREAD_COLOR)dst = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_AREA)dst2 = cv2.resize(src, dsize=(0, 0), fx=0.3, fy=0.7, interpolation=cv2.INTER_LINEAR)cv2.imshow(\"src\", src)cv2.imshow(\"dst\", dst)cv2.imshow(\"dst2\", dst2)cv2.waitKey()cv2.destroyAllWindows()세부 코드dst = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_AREA)dst2 = cv2.resize(src, dsize=(0, 0), fx=0.3, fy=0.7, interpolation=cv2.INTER_LINEAR)이미지 크기 조절 함수(cv2.resize)로 이미지의 크기를 변경할 수 있습니다.dst = cv2.resize(src, dstSize, fx, fy, interpolation)는 입력 이미지(src), 절대 크기(dstSize), 상대 크기(fx, fy), 보간법(interpolation)으로 출력 이미지(dst)을 생성합니다.절대 크기는 튜플(Tuple) 형식으로 (너비, 높이)의 값을 할당해 사용합니다.절대 크기는 다음과 같은 수식을 통해 계산됩니다.\\[dsize.width = round(fx \\times src.cols)\\]\\[dsize.height = round(fy \\times src.rows)\\]상대 크기는 절대 크기에 (0, 0)을 할당한 다음, 상대 크기의 값을 할당해 사용합니다.절대 크기에 (0, 0)을 할당하는 이유로는 fx와 fy에서 계산된 크기가 dsize에 할당되기 때문입니다.그러므로, 상대 크기로 이미지를 변경하기 위해서는 절대 크기에 0의 값을 할당해 사용합니다.상대 크기는 다음과 같은 수식을 통해 계산됩니다.\\[fx = dsize.width / src.cols\\]\\[fy = dsize.height / src.rows\\]보간법은 이미지의 크기를 변경하는 경우, 변형된 이미지의 픽셀은 추정해서 값을 할당해야 합니다.이미지의 비율을 변경하면 존재하지 않는 영역에 새로운 픽셀값을 매핑하거나 존재하는 픽셀들을 압축해서 새로운 값을 할당해야 합니다.이를 이미지 상에 존재하는 픽셀 데이터 \\((x_{i}, y_{i})\\)들에 대해 근사 함수 \\(f(x, y)\\)를 적용해서 새로운 픽셀 값을 구하는 것으로 이해할 수 있습니다.그러므로, 추정해야 하는 픽셀은 보간법을 이용하여 픽셀들의 값을 할당합니다.추가 정보interpolation 속성 속성 의미 cv2.INTER_NEAREST 이웃 보간법 cv2.INTER_LINEAR 쌍 선형 보간법 cv2.INTER_LINEAR_EXACT 비트 쌍 선형 보간법 cv2.INTER_CUBIC 바이큐빅 보간법 cv2.INTER_AREA 영역 보간법 cv2.INTER_LANCZOS4 Lanczos 보간법 일반적으로 쌍 선형 보간법이 가장 많이 사용됩니다.이미지를 확대하는 경우, 바이큐빅 보간법이나 쌍 선형 보간법을 가장 많이 사용합니다.이미지를 축소하는 경우, 영역 보간법을 가장 많이 사용합니다.영역 보간법에서 이미지를 확대하는 경우, 이웃 보간법과 비슷한 결과를 반환합니다.출력 결과" }, { "title": "OpenCV - 07. 확대 및 축소", "url": "/posts/opencv-7/", "categories": "OpenCV", "tags": "OpenCV, Zoom In, Zoom Out", "date": "2022-04-01 00:12:00 +0900", "snippet": "이미지 피라미드(Image Pyramid)입력 이미지는 항상 동일한 크기가 아니며 너무 작거나 너무 클 수도 있습니다.만약 알고리즘에서 요구하는 해상도가 있다면 입력 이미지의 크기를 변경해 영상 처리를 진행해야 합니다.또한, 검출하려는 객체가 너무 작거나 입력 이미지가 너무 큰 경우 입력 이미지 자체를 변환해서 영상 처리를 진행할 수도 있습니다.이미지 확대와 축소는 이미지 피라미드(Image pyramid)를 활용해 이미지의 크기를 원하는 단계까지 샘플링하는 작업입니다.이미지 피라미드의 의미는 이미지의 크기를 확대하거나 축소했을 때 이미지들의 형태가 피라미드와 같이 표현됩니다.원본 이미지에서 크기를 확대하는 것을 업 샘플링이라 하며 하위 단계의 이미지를 생성하게 됩니다.반대로 원본 이미지에서 크기를 축소하는 것을 다운 샘플링이라 하며, 상위 단계의 이미지를 생성하게 됩니다.이미지 피라미드로는 가우시안 피라미드(Gaussian Pyramid)와 라플라시안 피라미드(Laplacian pyramid)를 활용합니다.메인 코드import cv2src = cv2.imread(\"Image/6.jpg\", cv2.IMREAD_COLOR)height, width, channel = src.shapedst = cv2.pyrUp(src, dstsize=(width * 2, height * 2), borderType=cv2.BORDER_DEFAULT)dst2 = cv2.pyrDown(src)cv2.imshow(\"src\", src)cv2.imshow(\"dst\", dst)cv2.imshow(\"dst2\", dst2)cv2.waitKey()cv2.destroyAllWindows()세부 코드height, width, channel = src.shapeheight, width, channel = src.shape를 이용하여 해당 이미지의 높이, 너비, 채널의 값을 저장합니다.너비와 높이를 이용하여 출력 이미지 크기를 설정할 수 있습니다.dst = cv2.pyrUp(src, dstsize=(width * 2, height * 2), borderType=cv2.BORDER_DEFAULT)이미지 확대 함수(cv2.pyrUp)로 이미지를 2배 확대할 수 있습니다.dst = cv2.pyrUp(src, dstSize, borderType)는 입력 이미지(src), 출력 이미지 크기(dstSize), 테두리 외삽법(borderType)으로 출력 이미지(dst)을 생성합니다.출력 이미지 크기(dstSize)는 매우 세밀한 크기 조정을 필요로 할때 사용합니다.다음과 같은 조건을 만족하는 출력 이미지 크기만 사용할 수 있습니다.\\[\\left | dstSize.width - src.cols × 2 \\right | \\leq (dstSize.width \\ mod \\ 2)\\]\\[\\left | dstSize.height - src.rows × 2 \\right | \\leq (dstSize.height \\ mod \\ 2)\\]테두리 외삽법(borderType)은 이미지를 확대하거나 축소할 경우, 이미지 영역 밖의 픽셀은 추정해 값을 할당해야 합니다.그러므로, 테두리 외삽법은 이미지 밖의 픽셀을 외삽하는 데 사용되는 테두리 모드로, 외삽 방식을 설정합니다.dst2 = cv2.pyrDown(src)이미지 축소 함수(cv2.pyrUp)로 이미지를 2배 축소할 수 있습니다.dst = cv2.pyrDown(src, dstSize, borderType)는 입력 이미지(src), 출력 이미지 크기(dstSize), 테두리 외삽법(borderType)으로 출력 이미지(dst)을 생성합니다.출력 이미지 크기(dstSize)는 이미지 확대 함수에서 사용되는 방법과 동일하며, 다음과 같은 조건을 만족하는 출력 이미지 크기만 사용할 수 있습니다.\\[\\left | dstSize.width × 2 - src.cols \\right | \\leq 2\\]\\[\\left | dstSize.height × 2 - src.rows \\right | \\leq 2\\]추가 정보픽셀 외삽법 종류 속성 의미 cv2.BORDER_CONSTANT iiiiii | abcdefgh | iiiiiii cv2.BORDER_REPLICATE aaaaaa | abcdefgh | hhhhhhh cv2.BORDER_REFLECT fedcba | abcdefgh | hgfedcb cv2.BORDER_WRAP cdefgh | abcdefgh | abcdefg cv2.BORDER_REFLECT_101 gfedcb | abcdefgh | gfedcba cv2.BORDER_REFLECT101 gfedcb | abcdefgh | gfedcba cv2.BORDER_DEFAULT gfedcb | abcdefgh | gfedcba cv2.BORDER_TRANSPARENT uvwxyz | abcdefgh | ijklmno cv2.BORDER_ISOLATED 관심 영역 (ROI) 밖은 고려하지 않음 함수 추가 정보이미지 확대 함수는 BORDER_DEFAULT의 픽셀 외삽법만 사용할 수 있습니다.이미지 축소 함수는 BORDER_CONSTANT의 픽셀 외삽법을 제외한 나머지 플래그만 사용할 수 있습니다.출력 결과" }, { "title": "OpenCV - 06. 회전(Rotate)", "url": "/posts/opencv-6/", "categories": "OpenCV", "tags": "OpenCV, Rotate", "date": "2022-03-31 00:12:00 +0900", "snippet": "회전(Rotate)회전(Rotate)은 선형 변환 중 하나에 포함되며, 회전 변환 행렬(Rotation matrix)을 통해 변환이 진행됩니다.회전 변환 행렬은 임의의 점을 중심으로 물체를 회전시킵니다. 회전 변환 행렬의 일부는 반사 행렬(Reflection matrix)과 같은 값을 지닐 수 있습니다.2차원 유클리드 공간에서의 회전은 크게 두 가지 회전 행렬을 갖습니다. 좌푯값을 회전시키는 회전 행렬과 좌표 축을 회전시키는 회전 행렬이 있습니다.좌표 회전 행렬은 원점을 중심으로 좌푯값을 회전시켜 매핑하며, 좌표 축 회전 행렬은 원점을 중심으로 행렬 자체를 회전시켜 새로운 행렬의 값을 구성합니다.OpenCV의 회전 함수는 좌표 축의 회전 이동 행렬과 동일한 형태이며, 비율을 조정하거나 중심점의 기준을 변경하여 회전할 수 있습니다.메인 코드import cv2src = cv2.imread(\"Image/5.jpg\", cv2.IMREAD_COLOR)height, width, channel = src.shapematrix = cv2.getRotationMatrix2D((width/2, height/2), 90, 1)dst = cv2.warpAffine(src, matrix, (width, height))cv2.imshow(\"src\", src)cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()세부 코드src = cv2.imread(\"Image/5.jpg\", cv2.IMREAD_COLOR)이미지 입력 함수(cv2.imread)를 통해 원본 이미지로 사용할 src를 선언하고 로컬 경로에서 이미지 파일을 읽어 옵니다.height, width, channel = src.shapeheight, width, channel = src.shape를 이용하여 해당 이미지의 높이, 너비, 채널의 값을 저장합니다.높이와 너비를 이용하여 회전 중심점을 설정합니다.matrix = cv2.getRotationMatrix2D((width/2, height/2), 90, 1)2×3 회전 행렬 생성 함수(cv2.getRotationMatrix2D)로 회전 변환 행렬을 계산합니다.matrix = cv2.getRotationMatrix2D(center, angle, scale)는 중심점(center), 각도(angle), 비율(scale)로 매핑 변환 행렬(matrix)을 생성합니다.중심점(center)은 튜플(Tuple) 형태로 사용하며 회전의 기준점을 설정합니다.각도(angle)는 중심점을 기준으로 회전할 각도를 설정합니다.비율(scale)은 이미지의 확대 및 축소 비율을 설정합니다.dst = cv2.warpAffine(src, matrix, (width, height))아핀 변환 함수(cv2.warpAffine)로 회전 변환을 계산합니다.dst = cv2.warpAffine(src, M, dsize)는 원본 이미지(src)에 M(아핀 맵 행렬)을 적용하고 출력 이미지 크기(dsize)로 변형해서 출력 이미지(dst)를 반환합니다.아핀 맵 행렬(M)은 회전 행렬 생성 함수에서 반환된 매핑 변환 행렬을 사용합니다.출력 이미지 크기(dsize)는 튜플(Tuple) 형태로 사용하며 출력 이미지의 너비와 높이를 의미합니다.아핀 맵 행렬에 따라 회전된 이미지를 반환합니다.출력 결과" }, { "title": "OpenCV - 05. 대칭(Flip)", "url": "/posts/opencv-5/", "categories": "OpenCV", "tags": "OpenCV, Flip", "date": "2022-03-30 00:12:00 +0900", "snippet": "대칭 (Flip, Symmetry)대칭(Flip)은 기하학적인 측면에서 반사(reflection)의 의미를 갖습니다.2차원 유클리드 공간에서의 기하학적인 변환의 하나로 \\(R^2\\)(2차원 유클리드 공간) 위의 선형 변환을 진행합니다.대칭은 변환할 행렬(이미지)에 대해 2×2 행렬을 왼쪽 곱셈을 진행합니다. 즉, ‘p’ 형태의 물체에 Y축 대칭을 적용한다면 ‘q’ 형태를 갖게 됩니다.그러므로, 원본 행렬(이미지)에 각 축에 대한 대칭을 적용했을 때, 단순히 원본 행렬에서 축에 따라 재매핑을 적용하면 대칭된 행렬을 얻을 수 있습니다.메인 코드import cv2src = cv2.imread(\"Image/4.jpg\", cv2.IMREAD_COLOR)dst = cv2.flip(src, 0)cv2.imshow(\"src\", src)cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()세부 코드src = cv2.imread(\"Image/4.jpg\", cv2.IMREAD_COLOR)이미지 입력 함수(cv2.imread)를 통해 원본 이미지로 사용할 src를 선언하고 로컬 경로에서 이미지 파일을 읽어 옵니다.dst = cv2.flip(src, 0)대칭 함수(cv2.flip)로 이미지를 대칭할 수 있습니다.dst = cv2.flip(src, flipCode)는 원본 이미지(src)에 대칭 축(flipCode)을 기준으로 대칭한 출력 이미지(dst)를 반환합니다.대칭 축은 상수를 입력해 대칭할 축을 설정할 수 있습니다.flipCode &lt; 0은 XY 축 대칭(상하좌우 대칭)을 적용합니다.flipCode = 0은 X 축 대칭(상하 대칭)을 적용합니다.flipCode &gt; 0은 Y 축 대칭(좌우 대칭)을 적용합니다.cv2.imshow(\"src\", src)cv2.imshow(\"dst\", dst)cv2.waitKey()cv2.destroyAllWindows()이미지 표시 함수(cv2.imshow)와 키 입력 대기 함수(cv2.waitkey)로 윈도우 창에 이미지를 띄울 수 있습니다.이미지 표시 함수는 여러 개의 윈도우 창을 띄울 수 있으며, 동일한 이미지도 여러 개의 윈도우 창으로도 띄울 수 있습니다.단, 윈도우 창의 제목은 중복되지 않게 작성합니다.키 입력 대기 함수로 키가 입력될 때 까지 윈도우 창이 유지되도록 구성합니다.키 입력 이후, 모든 윈도우 창 제거 함수(cv2.destroyAllWindows)를 이용하여 모든 윈도우 창을 닫습니다.출력 결과" }, { "title": "OpenCV - 04. Vedio 출력", "url": "/posts/opencv-4/", "categories": "OpenCV", "tags": "OpenCV, Using Video", "date": "2022-03-29 00:12:00 +0900", "snippet": "비디오 출력동영상 파일에서 순차적으로 프레임을 읽어 이미지의 형태로 출력합니다.동영상 파일을 읽으려면 컴퓨터에 동영상 코덱을 읽을 수 있는 라이브러리가 설치돼 있어야 합니다.OpenCV는 FFmpeg를 지원하므로 *.avi나 *.mp4 등 다양한 형식의 동영상 파일을 손쉽게 읽을 수 있습니다.이미지 파일 중, GIF 확장자는 프레임이 존재하므로, 동영상 파일을 읽는 방법과 동일하게 처리합니다.메인 코드import cv2capture = cv2.VideoCapture(\"Image/3.mp4\")while cv2.waitKey(33) &lt; 0: if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT): capture.set(cv2.CAP_PROP_POS_FRAMES, 0) ret, frame = capture.read() cv2.imshow(\"VideoFrame\", frame)capture.release()cv2.destroyAllWindows()세부 코드capture = cv2.VideoCapture(\"Image/3.mp4\")비디오 출력 클래스(cv2.VideoCapture)를 통해 동영상 파일에서 정보를 받아올 수 있습니다.capture = cv2.VideoCapture(fileName)는 파일 경로(fileName)의 동영상 파일을 불러옵니다.앞선, Python OpenCV 강좌 : 제 2강 - 카메라 출력에서 사용한 클래스와 동일한 클래스를 사용하며, 진행 방식도 동일합니다.단, 카메라의 장치 번호가 아닌, 동영상 파일의 경로를 지정합니다.if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)): capture.set(cv2.CAP_PROP_POS_FRAMES, 0)비디오 속성 반환 메서드(capture.get)로 비디오의 속성을 반환합니다.비디오의 정보 중, 동영상의 현재 프레임 수(cv2.CAP_PROP_POS_FRAMES)와 동영상의 총 프레임 수(cv2.CAP_PROP_FRAME_COUNT)를 받아옵니다.분기문(if)을 이용하여 동영상의 현재 프레임 수와 동영상의 총 프레임 수를 비교합니다.현재 프레임의 수가 총 프레임 수가 같다면, 현재 재생되고 있는 프레임은 가장 마지막이 됩니다.마지막 프레임은 동영상이 종료되는 시점이 되므로, 비디오 속성 설정 메서드(capture.get)로 동영상의 현재 프레임을 초기화합니다. Tip : 또는, 동영상 파일 읽기 메서드(capture.open)를 이용하여 다시 동영상 파일을 불러올 수도 있습니다.추가 정보VideoCapture 메서드 메서드 의미 capture.isOpened() 동영상 파일 열기 성공 여부 확인 capture.open(filename) 동영상 파일 열기 capture.set(propid, value) 동영상 속성 설정 capture.get(propid) 동영상 속성 반환 capture.release() 동영상 파일을 닫고 메모리 해제 VideoCapture 속성 속성 의미 비고 cv2.CAP_PROP_FRAME_WIDTH 프레임의 너비 - cv2.CAP_PROP_FRAME_HEIGHT 프레임의 높이 - cv2.CAP_PROP_FRAME_COUNT 총 프레임 수 - cv2.CAP_PROP_FPS 프레임 속도 - cv2.CAP_PROP_FOURCC 코덱 코드 - cv2.CAP_PROP_BRIGHTNESS 이미지 밝기 카메라만 해당 cv2.CAP_PROP_CONTRAST 이미지 대비 카메라만 해당 cv2.CAP_PROP_SATURATION 이미지 채도 카메라만 해당 cv2.CAP_PROP_HUE 이미지 색상 카메라만 해당 cv2.CAP_PROP_GAIN 이미지 게인 카메라만 해당 cv2.CAP_PROP_EXPOSURE 이미지 노출 카메라만 해당 cv2.CAP_PROP_POS_MSEC 프레임 재생 시간 ms 반환 cv2.CAP_PROP_POS_FRAMES 현재 프레임 프레임의 총 개수 미만 CAP_PROP_POS_AVI_RATIO 비디오 파일 상대 위치 0 = 시작, 1 = 끝 출력 결과" }, { "title": "OpenCV - 03. Image 출력", "url": "/posts/opencv-3/", "categories": "OpenCV", "tags": "OpenCV, Using Image", "date": "2022-03-28 00:12:00 +0900", "snippet": "이미지 출력OpenCV는 래스터 그래픽스 이미지 파일 포맷을 쉽게 불러올 수 있는 별도의 함수를 제공합니다.이 함수는 불러온 압축 해제된 이미지 데이터 구조에 필요한 메모리 할당과 같은 복잡한 작업을 처리하며, 파일 시그니처(File Signature)를 읽어 적절한 코덱을 결정합니다.OpenCV에서 이미지를 불러올 때는 확장자를 확인하는 방식이 아닌 파일 시그니처를 읽어 파일의 포맷을 분석합니다.파일 시그니처는 파일 매직 넘버(File Magic Number)라고도 하며, 각 파일 형식마다 몇 개의 바이트가 지정되어 있습니다.예를 들어, PNG 확장자의 경우 89 50 4E 47 … 형태로 파일 헤더에 포함되어 있습니다.이미지 입력 함수는 운영체제의 코덱을 사용해 운영체제 별로 픽셀값이 다를 수 있습니다.메인 코드import cv2image = cv2.imread(\"Image/2.jpg\", cv2.IMREAD_ANYCOLOR)cv2.imshow(\"Moon\", image)cv2.waitKey()cv2.destroyAllWindows()세부 코드image = cv2.imread(\"Image/2.jpg\", cv2.IMREAD_ANYCOLOR)이미지 입력 함수(cv2.imread)를 통해 로컬 경로의 이미지 파일을 읽어올 수 있습니다.image = cv2.imread(fileName, flags)는 파일 경로(fileName)의 이미지 파일을 플래그(flags) 설정에 따라 불러옵니다.파일 경로(fileName)는 상대 경로 또는 절대 경로를 사용하여 이미지를 불러옵니다.flags은 이미지를 초기에 불러올 때 적용할 초기 상태를 의미합니다. flags cv2.IMREAD_UNCHANGED : 원본 사용 cv2.IMREAD_GRAYSCALE : 1 채널, 그레이스케일 적용 cv2.IMREAD_COLOR : 3 채널, BGR 이미지 사용 cv2.IMREAD_ANYDEPTH : 이미지에 따라 정밀도를 16/32비트 또는 8비트로 사용 cv2.IMREAD_ANYCOLOR : 가능한 3 채널, 색상 이미지로 사용 cv2.IMREAD_REDUCED_GRAYSCALE_2 : 1 채널, 1/2 크기, 그레이스케일 적용 cv2.IMREAD_REDUCED_GRAYSCALE_4 : 1 채널, 1/4 크기, 그레이스케일 적용 cv2.IMREAD_REDUCED_GRAYSCALE_8 : 1 채널, 1/8 크기, 그레이스케일 적용 cv2.IMREAD_REDUCED_COLOR_2 : 3 채널, 1/2 크기, BGR 이미지 사용 cv2.IMREAD_REDUCED_COLOR_4 : 3 채널, 1/4 크기, BGR 이미지 사용 cv2.IMREAD_REDUCED_COLOR_8 : 3 채널, 1/8 크기, BGR 이미지 사용 cv2.imshow(\"Moon\", image)cv2.waitKey()cv2.destroyAllWindows()이미지 표시 함수(cv2.imshow)와 키 입력 대기 함수(cv2.waitkey)로 윈도우 창에 이미지를 띄울 수 있습니다.키 입력 대기 함수를 사용하지 않을 경우, 윈도우 창이 유지되지 않고 프로그램이 종료됩니다.키 입력 이후, 모든 윈도우 창 제거 함수(cv2.destroyAllWindows)를 이용하여 모든 윈도우 창을 닫습니다.추가 정보height, width channel = image.shapeprint(height, width , channel) 결과 1920 1280 3height, width , channel = image.shape를 이용하여 해당 이미지의 높이, 너비, 채널의 값을 확인할 수 있습니다.이미지의 속성은 크기, 정밀도, 채널을 주요한 속성으로 사용합니다. 크기 : 이미지의 높이와 너비를 의미합니다. 정밀도 : 이미지의 처리 결과의 정밀성을 의미합니다. 채널 : 이미지의 색상 정보를 의미합니다. Tip : 유효 비트가 많을 수록 더 정밀해집니다. Tip : 채널이 3일 경우, 다색 이미지입니다. 채널이 1일 경우, 단색 이미지입니다. 출력 결과" }, { "title": "OpenCV - 02. Camera 출력", "url": "/posts/opencv-2/", "categories": "OpenCV", "tags": "OpenCV, Using Camera", "date": "2022-03-27 00:12:00 +0900", "snippet": "카메라 출력OpenCV를 이용하면 카메라 출력을 쉽게 사용할 수 있습니다.카메라 출력은 카메라가 스트리밍 형태로 동작할 수 있을 때 사용합니다.즉, 저장된 이미지나 동영상 파일이 아니라 데이터를 실시간으로 받아오고 분석해야 하는 경우 카메라를 이용해 데이터를 처리합니다.카메라를 사용해 데이터를 받아오기 때문에 연결된 카메라의 장치 번호를 통해 받아오며, 사용중인 플랫폼에서 카메라에 대한 접근 권한이 허용되어야 합니다.메인 코드import cv2capture = cv2.VideoCapture(0)capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)while cv2.waitKey(33) &lt; 0: ret, frame = capture.read() cv2.imshow(\"VideoFrame\", frame)capture.release()cv2.destroyAllWindows()세부 코드capture = cv2.VideoCapture(0)비디오 출력 클래스(cv2.VideoCapture)를 통해 내장 카메라 또는 외장 카메라에서 정보를 받아올 수 있습니다.cv2.VideoCapture(index)로 카메라의 장치 번호(ID)와 연결합니다. index는 카메라의 장치 번호를 의미합니다.노트북의 경우, 일반적으로 내장 카메라가 존재하므로 노트북 카메라의 장치 번호는 0이 됩니다.카메라를 추가적으로 연결하여 외장 카메라를 사용하는 경우, 장치 번호가 1~n까지 순차적으로 할당됩니다.capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)카메라 속성 설정 메서드(capture.set)로 카메라의 속성을 설정합니다.capture.set(propid, value)로 카메라의 속성(propid)과 값(value)을 설정할 수 있습니다.propid은 변경하려는 카메라 설정을 의미합니다.value은 변경하려는 카메라 설정의 속성값을 의미합니다.예제에서는 카메라의 너비를 640, 높이를 480으로 변경합니다.while cv2.waitKey(33) &lt; 0: ret, frame = capture.read() cv2.imshow(\"VideoFrame\", frame)반복문(While)을 활용하여 카메라에서 프레임을 지속적으로 받아옵니다.키 입력 대기 함수(cv2.waitkey)는 지정된 시간 동안 키 입력이 있을 때까지 프로그램을 지연시킵니다.cv2.waitkey(delay)로 키 입력을 기다립니다. delay는 지연 시간을 의미합니다.밀리초 단위의 시간 동안 키 입력을 기다리며 그 시간동안 키 입력이 없을 경우 다음 구문을 실행합니다.키 입력 대기 함수는 입력된 키의 아스키 코드 값을 반환합니다.즉, 어떤 키라도 입력되기 전까지 33ms마다 반복문을 실행합니다. Tip : delay가 0일 경우, 지속적으로 키 입력을 검사하여 프레임이 넘어가지 않습니다. Tip : while cv2.waitKey(33) != ord('q'):으로 사용할 경우, q가 입력될 때 while문을 종료합니다.프레임 읽기 메서드(capture.read)를 이용하여 카메라의 상태 및 프레임을 받아옵니다.ret은 카메라의 상태가 저장되며 정상 작동할 경우 True를 반환합니다. 작동하지 않을 경우 False를 반환합니다.frame에 현재 시점의 프레임이 저장됩니다.이미지 표시 함수(cv2.imshow)를 이용하여 특정 윈도우 창에 이미지를 띄웁니다.cv2.imshow(winname, mat)으로 윈도우 창의 제목(winname)과 이미지(mat)를 할당합니다.winname은 문자열로 표시하며, 할당한 문자열이 변수와 비슷한 역할을 합니다.mat은 이미지를 의미하며, 윈도우 창에 할당할 이미지를 의미합니다.VideoFrame 이름을 갖는 윈도우 창에 프레임이 표시됩니다.capture.release()cv2.destroyAllWindows()메모리 해제 메서드(capture.relase)로 카메라 장치에서 받아온 메모리를 해제합니다.모든 윈도우 창 제거 함수(cv2.destroyAllWindows)를 이용하여 모든 윈도우 창을 닫습니다.만약, 특정 윈도우 창만 닫는다면, cv2.destroyWindow(winname)으로 특정 윈도우 창만 닫을 수 있습니다." }, { "title": "OpenCV - 01. OpenCV 설치", "url": "/posts/opencv-1/", "categories": "OpenCV", "tags": "OpenCV, OpenCV Install", "date": "2022-03-27 00:12:00 +0900", "snippet": "OpenCVOpenCV는 Open Source Computer Vision Library의 약어로 오픈소스 컴퓨터 비전 라이브러리입니다.실시간 영상 처리에 중점을 둔 영상 처리 라이브러리로서, Apache 2.0 라이선스하에 배포되어 학술적 용도 외에도 상업적 용도로도 사용할 수 있습니다.OpenCV는 계산 효율성과 실시간 처리에 중점을 두고 설계되었습니다.500가지가 넘는 알고리즘이 최적화돼 있으며 이 알고리즘을 구성하거나 지원하는 함수는 알고리즘 수의 10배가 넘습니다.물체 인식, 얼굴 인식, 제스처 인식을 비롯해 자율주행 자동차, OCR 판독기, 불량 검사기 등에 활용할 수 있습니다.본 실습 예제는 Python-OpenCV 4.5.1.48에 맞추어져 있습니다.코드 및 설명은 윤대희님 블로그를 참고 및 정리하였습니다.OpenCV 설치Python OpenCV는 다음과 같은 네 종류의 패키지를 제공합니다.opencv-pythonopencv-contrib-pythonopencv-python-headlessopencv-contrib-python-headlesscontrib가 포함된 패키지는 확장 모듈이 포함된 패키지이며, 추가 모듈이 포함된 OpenCV를 설치합니다headless가 포함된 패키지는 GUI 라이브러리 종속성이 없어 서버 환경(Docker, Cloud)에서 사용할 수 있는 OpenCV를 설치합니다.특별한 경우가 아니라면, 일반적으로 opencv-python 패키지를 사용합니다.OpenCV는 pip를 통하여 설치할 수 있습니다.명령 프롬프트나 터미널에서 python -m pip install opencv-python 명령어로 설치할 수 있습니다.import cv2print(cv2.__version__) 결과 4.5.1정상적으로 설치가 완료되었다면 설치한 OpenCV의 버전인 4.5.1이 출력됩니다.Python 플랫폼본 Python-OpenCV 예제에서 사용될 이미지의 경로는 위와 같습니다.D:\\Python\\Image 폴더 안에 이미지 및 동영상을 저장하여 사용합니다.IDLE를 사용할 경우, 상대 경로를 이용하여 \"Image/파일명\"으로 이미지를 불러올 수 있습니다.Visual Studio를 사용할 경우, 절대 경로를 이용하여 \"D:/Python/Image/파일명\"으로 이미지를 불러올 수 있습니다.Anaconda를 이용하는 경우에도 동일합니다." }, { "title": "Github 로컬 저장소와 연동하기 💾", "url": "/posts/Github-%EB%A1%9C%EC%BB%AC-%EC%A0%80%EC%9E%A5%EC%86%8C%EC%99%80-%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0/", "categories": "Git & Github", "tags": "Github, Local Storage, Repository", "date": "2022-03-26 00:12:00 +0900", "snippet": " 기존에 실습을 진행했던 React 자료를 github 저장소에 업로드하기 위해서 로컬 저장소와 github을 연결했다.1. github(깃허브) 란?🧐 git을 사용하는 프로젝트를 지원하는 웹 호스팅 서비스이다. git을 업로드 할 수 있어 공동 작업에 유용하다는 점을 기억하자.❗2. Repository 생성 github는 로컬 저장소에 있는 폴더와 github 페이지에 만든 Repository를 연결할 수 있다. 우선 github의 첫 페이지에서 New 버튼을 통해 Repository를 생성한다.* Repository는 말 그대로 저장소라는 뜻으로 파일들을 저장하는 폴더라고 생각하자. 그리고, 앞서 언급한 README.md 파일을 생성한 것 처럼 Repository를 생성하면 된다. 주의 ❗ 저장소의 이름은 영어와 _만 사용 가능하다. hello-react라는 이름으로 저장소를 만들었으니, github 저장소와 로컬 저장소를 연결해보자.3. Repository 연결 github를 연결하기 위해서 올리고자 하는 폴더에서 마우스 우클릭 후 git Bash Here을 클릭한다. 누르면 아래와 같은 bash 창이 열리게 된다. 우선 bash에 git config 명령을 사용하여 git 사용자 정보를 설정하자.// 자신의 깃허브 이름$ git config --global user.name \"daekyeong\"// 자신의 이베일 주소$ git config --global user.email daekyeongp96@gmail.com 사용자 정보는 최초 1회만 실행하면 다음부터 자동으로 설정된다. 그 후, 아래의 명령어를 통해 README.md를 생성해보자.$ git init // 👉 github와 연동시킬 .git 파일 추가 (master branch 생성)$ git add README.md // 👉 README.md 파일 추가$ git commit -m \"작성하고 싶은 메세지\" // 👉 README.md 파일에 \"작성하고 싶은 메세지\" 커밋을 달아준다.$ git branch -M master // 👉 현재 branch 위치를 master로 지정$ git remote add origin {저장소 주소} // 👉 폴더와 github url을 연동$ git push -u origin master // 👉 폴더에 있는 파일을 master branch로 올린다. 작성하고 싶은 메세지를 React Example &amp; First commit로 했기 때문에 아래와 같은 결과를 확인했다.4. Repository에 파일 업로드 Repository에 파일을 업로드 하는 과정은 다음과 같다.$ git pull origin master // 👉 master branch에 있는 파일들을 끌어온다.$ git add . // 👉모든 파일을 업로드$ git commit -m \"원하는 메세지\" // 👉 업로드 파일에 달아줄 커밋 메세지 작성$ git push origin master // 👉 master branch에 파일을 업로드 이렇게 진행하면 github Repository에 정상적으로 파일이 업로드 된 것을 확인할 수 있다. 하지만 파일을 올리는 과정 중 몇 가지 오류가 발생했다.5. Error 해결 ❗ 첫 번째 오류는 README.md 파일을 생성할 때 발생했다. 위와 같은에러가 발생했는데, 문서의 개행 문자를 처리하는 OS 차이 때문에 발생하는 것이다. 다음과 같은코드를 사용하여 해결할 수 있다. 두 번째 오류는 git push 명령을 사용 했을 때 발생했다. 이 오류는 소스 파일 사이즈 보다 postBuffer size가 작은 것이므로 다음과 같은 명령을 통해 해결했다.처음 github에 리액트를 공부했던 내용을 업로드 했는데 처음이라 조금 막히는 부분이 있었지만, 구글링을 통해 빠르게 해결할 수 있었다.앞으로 공부하거나 실습한 자료들을 많이 업로드해서 기록을 남겨야겠다 ㅎㅎ 😊end" }, { "title": "Github 나만의 프로필(Profile) 만들기 🧑‍🎓", "url": "/posts/Github-%EB%82%98%EB%A7%8C%EC%9D%98-%ED%94%84%EB%A1%9C%ED%95%84(Profile)-%EB%A7%8C%EB%93%A4%EA%B8%B0/", "categories": "Git & Github", "tags": "Github, Profile", "date": "2022-03-26 00:05:00 +0900", "snippet": "1. Github Repository 생성👏 프로필용 Github Repository를 생성하는데 github에서 아래와 같이 설명하고 있다. GitHub will display your profile README on your profile page if all of the following are true. You’ve created a repository with a name that matches your GitHub username. The repository is public. The repository contains a file named README.md in its root. The README.md file contains any content. 즉, Repository 이름을 내 github 아이디와 같게 생성하고 Repository를 public으로 설정하면 된다. 위의 그림과 같이 설정하고 Repository를 생성하면 README.md 파일이 생성된다.TIP👍 README.md 파일을 편집할 때 아래의 그림과 같이 코드를 작성하는 화면이 나온다. Edit file 오른쪽에 Preview를 누르면 Commit을 하기 전에 미리보기가 가능하다. 하지만, 이조차도 왔다갔다 너무 귀찮다..그래서 찾아본 결과 dillinger 사이트를 이용하면 작성한 Markdown 코드의 결과를 바로 확인할 수 있다. 2. 프로필 만들기2.1 Capsule render 사용 방법은 매우 간단하다.```Javascript// 내가 사용한 코드👉 출처 : https://github.com/kyechan99/capsule-render## 2.2 배지 &amp; 아이콘 사용하기* 아래의 그림처럼 다른 블로그 처럼 **배지**로 멋있게 정리하고 싶었다.![shields](https://images.velog.io/images/daekyeong/post/a1f738a2-141b-4f05-83eb-87473bc73f51/image.png)* **배지** https://shields.io/* **아이콘** https://simpleicons.org/* 위의 링크를 통해 원하는 **배지와 아이콘**을 사용할 수 있다.* 내가 사용한 **Javascript**의 코드는 다음과 같다.```Javascript&lt;img src=\"https://img.shields.io/badge/Javascript-ffb13b?style=flat-square&amp;logo=javascript&amp;logoColor=white\"/&gt;&lt;/a&gt;&amp;nbsp 위의 코드만 보면 햇갈릴 수 있는데 쉽게 설명하면 다음과 같다.&lt;img src=\"https://img.shields.io/badge/{사용할 텍스트-simpleicons 코드}style=flat-square&amp;logo={simpleicons 아이콘이름}&amp;logoColor=white\"/&gt;&lt;/a&gt;&amp;nbsp Tech Blog, Gmail과 같이 링크를 걸기위해선 a 태그를 이용하면 된다.&lt;a href=\"{링크 주소}\"&gt;&lt;img src=\"https://img.shields.io/badge/{사용할 텍스트-simpleicons 코드}style=flat-square&amp;logo={simpleicons 아이콘이름}&amp;logoColor=white&amp;link={링크 주소}\"/&gt;&lt;/a&gt;&amp;nbsp2.3 Github Stats Github 통계를 사용하여 커밋, 기여, 이슈 등 계산 결과를 한 눈에 볼 수 있다. 오늘 처음 시작해서 Total Commits가 2 이다. ㅋㅋ 😁 사용 방법은 아래의 코드와 같다.[![Anurag's GitHub stats](https://github-readme-stats.vercel.app/api?username={github 아이디}&amp;hide_title=true&amp;show_icons=true&amp;include_all_commits=true&amp;disable_animations=true&amp;theme=vue)](https://github.com/anuraghazra/github-readme-stats)👉 출처 : https://github.com/anuraghazra/github-readme-stats 위의 사이트를 들어가 보면 사용법과 다양한 테마를 사용할 수 있는 방법이 친절하게 설명되어있다.2.4 Solved.ac 랭크 백준을 공부하는 사람들에게 자극? 목표?를 주는 것 같다. https://solved.ac/ 에서 백준 아이디와 연동하고 아래의 코드에 자신의 아이디를 넣으면 된다.[![Solved.ac 프로필](http://mazassumnida.wtf/api/v2/generate_badge?boj={solved 아이디})](https://solved.ac/{solved 아이디})👉 출처 : https://github.com/mazassumnida/mazassumnida오늘부터 예제 실습을 시작으로 내가 하는 모든 것들을 기록해보고 싶어서 github을 시작했다.아직 너무 어색하긴 하지만 꾸며야 재미도 있을 것 같았는데 너무 멋있게 꾸며져서 만족스럽다 ㅎㅎ👏Stats도 점점 늘려가고 Solved 랭크도 얼른 높아지는 날이 다가오길 😁end" }, { "title": "Git 기초 ✔️", "url": "/posts/Git-%EA%B8%B0%EC%B4%88/", "categories": "Git & Github", "tags": "Git", "date": "2022-03-26 00:02:00 +0900", "snippet": "Git 이란?버전관리시스템 💾 형상 관리 도구 중 하나로, 대형 프로젝트를 효율적으로 관리할 수 있게 해주는 무료 소프트웨어이다. 여러 명이 branch를 만들어 merge가 가능하기 때문에 동시 다발적으로 병렬 개발이 가능하다. 분산 버전관리이기 대문에 인터넷이 연결되지 않은 곳에서 개발을 진행할 수 있으며, 저장소가 날라가도 다시 원상복구 가능하다.Git-Flow Workflow Git은 병렬적 브랜치 관리전략을 사용하기 때문에 브랜치를 생성하고 삭제하는 것이 쉽다. 아래의 그림은 Git-Flow Workflow를 시각화한 그림이다.(출처: https://expressus.io/diagrams/git-flow-workflow-diagram-template) Master: 처음 생성하면 Master로 생성되는데, Master라는 것은 언제든지 Release가 가능한 상태를 뜻한다. 즉, 수정하고 있는 코드 들은 브랜치를 만들어 작업을 해야한다. ❗❗ Hotfix: Master 브랜치에서 파생된 브랜치이다. Master에서 오류, 버그가 발견되었을 때 Master에서 브랜치를 생성한 후, 오류, 버그를 수정한 다음에 다시 Master에 Merge를 한다. 즉, 쉽게 말해 폴더라고 생각하면 된다. Release: Develop 브랜치에서 파생되어 관리를 하고, 향후 Develop 브랜치로 Merge 한다. Develop: 실제로 개발을 하는 브랜치로, 대부분 작업 과정은 Develop에서 바로 Master로 가지 않고 Release를 거쳐서 Master로 Merge한다. Feature: 부수적인 기능, 새로운 기능을 추가할 때 개발하는 브랜치로, 개발이 끝나면 Develop에 Merge 된다. 그런데, Feature 브랜치는 하나의 브랜치가 아닌 폴더의 형태다. Why? 협업하는 경우는 여러 사람이 여러 기능을 개발할 경우도 있기 때문이다. 동작 원리✔ 스냅샷(SnapShot) 코드를 저장할 때마다 그 시점 코드의 스냅샷을 저장한다. 즉, 파일 자체를 저장하는것 보다 실제 프로젝트를 커밋하여 적용하는 순간이 중요하기 때문에 그 수정 내역 자체를 저장한다. 변경되지 않은 파일은 저장하지 않고 이전에 저정한 동일한 파일을 링크로 걸어둠 (링크정보만 저장하기 때문에 용량이 작다) 체크섬(Checksum) 데이터를 저장하기 전 *체크섬을 구해서 데이터를 관리한다.*체크섬: 중복검사의 형태로 순환중복검사를 뜻함. *SHA-1 해시 사용 *SHA-1 해시: 16진수 문자 40개로 구성된 문자열 (파일의 내용 또는 디렉토리 구조를 기반으로 계산한다) 파일이름 대신 컨텐츠의 해시 값을 저장 (파일명이 변경되어도 내용이 동일하면 같은 해시를 갖는다) Section Working directory: clon을 하게 되면 working directory가 생성된다. 즉, 내 컴퓨터에 작업할 파일이 있는 디렉토리 Staging area: local 저장소 같은 느낌으로, 커밋(Commit)을 수행할 파일들이 올라가는 영역이다. 즉, Staging area에는 생성된 저장소(Repository)와 관리하고 있는 파일들의 목록이 있음 Working directory에서 파일을 생성하고 등록하게 되면 Staging area에 추가되지만, 여기에 추가가 된다고 해도 저장소(Repository)에는 변경사항이 저장 되지 않음. 오늘 git을 처음 살펴보았는데 왜 많은 사람들이 git! git! 하는지 알게됐다.. 왜 이렇게 편한걸 우리 연구실에서는 사용하지 않았을까??😒 서로 버전도 다르고 코드 스타일도 달라서 코드를 합칠때 엄청 고생했던 기억이 떠올랐다..😢 그때 git을 쓰고 있었다면 어땠을까??ㅠㅠ 지금부터라도 나중에 팀원들과 협업할 때 그리고 나를 위해서 git을 습관화 하도록 공부 열심히 해야겠다.❗❗end" }, { "title": "Markdown(마크다운) 사용법 ✍️", "url": "/posts/Markdown(%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4)-%EC%82%AC%EC%9A%A9%EB%B2%95-%EB%B3%B5%EC%82%AC%EB%B3%B8/", "categories": "Markdown", "tags": "Markdown, 마크다운", "date": "2022-03-25 12:15:33 +0900", "snippet": "마크다운이란 마크다운(markdown)은 일반 텍스트 문서의 양식을 편집하는 문법이다. README 파일이나 온라인 문서, 혹은 일반 텍스트 편집기로 문서 양식을 편집할 때 쓰인다. 마크다운을 이용해 작성된 문서는 쉽게 HTML 등 다른 문서형태로 변환이 가능하다.-위키백과📖마크다운 사용법1. 제목 (Header)h1 부터 h6까지 표현할 수 있고, #의 개수로 h1 ~ h6 표현이 가능하다.🖊 마크다운 작성 방법# h1## h2### h3#### h4##### h5###### h6👉 결과h1h2h3h4h5h6❗ h1과 h2는 다음과 같은 방법으로도 사용가능하다.=, -를 각각 2개 이상 사용하면 h1, h2의 #을 대신해서 사용할 수 있다. 여러 개를 사용해도 h1, h2 효과가 적용됩니다.🖊 마크다운 작성 방법h1==h2--hyphen 여러 개----------👉 결과h1==h2–hyphen 여러 개———-2. 문단 간격기본적으로 문단 간격은 &lt;br/&gt;을 사용하여 줄 바꿈으로 나타내고, 여러 번 줄 바꿈시 &lt;br/&gt;을 여러번 사용하면 됩니다.🖊 마크다운 작성 방법문단&lt;br/&gt;문단&lt;br/&gt;&lt;br/&gt;문단👉 결과문단문단문단3. 목록(리스트)목록은 순서를 표기하는 목록과 순서가 없는 목록 두 가지를 작성할 수 있다.3.1 순서를 표기하는 목록순서있는 목록은 숫자와 점을 사용한다.🖊 마크다운 작성 방법1. 첫 번째2. 두 번째3. 세 번째👉 결과 첫 번째 두 번째 세 번째 3.2 순서가 없는 목록(글머리 기호) -, *, +를 사용하여 작성한다. (셋 다 모두 동일한 기능) 인라인 코드와 블럭 코드도 작성할 수 있고, Tab, Space bar를 통해 들여쓰기할 수 있다. 🖊 마크다운 작성 방법- 목록 1 - 목록 1.1 - 목록 1.2- 목록 2\t\t Tab 두번 하여 코드 블럭 생성* 목록 3+ 목록 4\t+ `인라인 코드` \t+ Tab키를 하면 다른 모양으로 표현 가능 ```　\t\t블럭 코드\t\t```　👉 결과 목록 1 목록 1.1 목록 1.2 목록 2 Tab 하여 코드 블럭 생성 목록 3 목록 4 인라인 코드 \t+ Tab키를 사용하면 다른 모양으로 표현 가능 　 블럭 코드 　 4. 폰트 강조(스타일) 굵게, 기울이기, 취소선 등 기본적인 스타일은 아래와 같이 작성할 수 있다. 🖊 마크다운 작성 방법__굵게__**굵게**_기울여 쓰기_*기울여 쓰기*~~취소선~~👉 결과굵게굵게기울여 쓰기기울여 쓰기취소선5. 인용문인용문은 &gt;를 사용하여 작성한다.🖊 마크다운 작성 방법&gt; 인용문- 작성자&gt; 인용문 작성&gt;&gt; `&gt;`의 갯수에 따라&gt;&gt;&gt; 중중첩문 가능👉 결과 인용문 작성자 인용문 작성 &gt;의 갯수에 따라 중중첩문 가능 6. 인라인 코드｀을 사용하여 인라인 코드를 작성할 수 있다.🖊 마크다운 작성 방법`인라인 코드 블럭`👉 결과인라인 코드 블럭7. 코드 블럭｀을 세 개 사용하여 인라인 코드를 작성할 수 있다.🖊 마크다운 작성 방법```　위 아래 3개로 코드 블럭 생성```　👉 결과위 아래 3개로 코드 블럭 생성❗ 구문 강조(Syntax Highlighting)🖊 마크다운 작성 방법아래와 같이 ｀ 3개 뒤에 컴퓨터 언어 이름을 넣으면 해당 언어 형식으로 변환해 준다.```javascriptlet sum = (Num1, Num2) =&gt; { return Num1 + Num2;};sum(100, 200);```　```pythonlist = ['1', '2', '3']for num in list: print(num)```　👉 결과let sum = (Num1, Num2) =&gt; { return Num1 + Num2;};sum(100, 200);list = ['1', '2', '3']for num in list: print(num)8. 링크(Link)인라인 링크와 URL 링크, 참조 링크로 나타낼 수 있다.🖊 마크다운 작성 방법인라인 링크는 다음과 같다.[인라인 링크](https://velog.io/@daekyeong)url 링크는 다음과 같다.&lt;https://velog.io/@daekyeong&gt;참조 링크는 다음과 같다.[참조 한 링크 사용함][Dekay][Dekay]: https://velog.io/@daekyeong👉 결과인라인 링크는 다음과 같다.인라인 링크url 링크는 다음과 같다.https://velog.io/@daekyeong참조 링크는 다음과 같다.[참조 한 링크 사용함][Dekay][Dekay]: https://velog.io/@daekyeong9. 이미지 링크(Image Link)이미지 링크는 아래와 같이 사용할 수 있다.🖊 마크다운 작성 방법![이미지 설명](이미지 링크)![Dekay Blog](https://media.vlpt.us/images/velog/profile/9aa07f66-5fcd-41f4-84f2-91d73afcec28/green%20favicon.png?w=240)👉 결과❗ 이미지에 링크를 걸고 싶은 경우는 아래와 같이 사용할 수 있다. (Image Size는 10MB 이하만 가능하다)🖊 마크다운 작성 방법[![이미지 설명](이미지 링크)](연결하고자하는 url \"마우스 오버 시 나타낼 Title\")👉 결과10. 수평선(Horizontal Rules)*,-,_ 등 3개 이상 입력하여 사용한다.띄어쓰기를 중간에 사용해도 정상적으로 사용할 수 있지만, -은 헤더로 인식할 수 있기 때문에 주의해야한다.🖊 마크다운 작성 방법***-------- -- -- -- -- -- --👉 결과***——– – – – – – –11. 탈출 문자(Escaping Chracters)텍스트 형식에 사용되는 문자나 기호들을 표현하기 위해서는 \\ 백슬래시(Backslash)를 사용한다.🖊 마크다운 작성 방법\\* 백슬래시를 사용하면 정렬되지 않은 목록의 글머리 기호를 표현할 수 있다.👉 결과* 백슬래시를 사용하면 정렬되지 않은 목록의 글머리 기호를 표현할 수 있다.12. HTML마크다운(Markdown)에서 HTML 태그 또한 사용할 수 있다.🖊 마크다운 작성 방법&lt;strong&gt;굵은 제목&lt;/strong&gt;&lt;h3&gt;제목1&lt;/h3&gt;&lt;a href=\"http://velog.io/@daekyeong\"&gt;Dekay Blog&lt;/a&gt;&lt;br&gt;&lt;font color=\"blue\"&gt;Blue&lt;/font&gt;👉 결과굵은 제목제목1Dekay BlogBlue13. 표(Table)테이블은 아래와 같이 작성합니다.| 파이프(Pipe)로 구분하며, 4. 폰트 강조(스타일) 에서 다루었던 스타일 적용이 가능하다. 또한 -하이픈(hyphen)으로 구분된 곳 각각 왼쪽, 양쪽, 오른쪽에 :세미콜론을 붙이면 순서대로 왼쪽 정렬, 가운데 정렬, 오른쪽 정렬이 가능하다.🖊 마크다운 작성 방법|왼쪽 정렬|가운데 정렬|오른쪽 정렬||:---|:---:|---:||**Header**|_Title_|Title||`Paragraph`|Text|Text|👉 결과|왼쪽 정렬|가운데 정렬|오른쪽 정렬||:—|:—:|—:||Header|Title|Title||Paragraph|Text|Text|14. 체크박스(Check Box)-, *, + 뒤에 띄어쓰기 후 빈 공간을 가진 [ ]대괄호를 사용한다.박스에 체크하고 싶다면 [x] 빈 공간 대신 x키를 입력하면 된다.🖊 마크다운 작성 방법- [ ] 꾸준하게 공부하기- [x] 강의 듣기- [ ] 코딩 연습👉 결과 꾸준하게 공부하기 강의 듣기 코딩 연습 15. 이모티콘 모음 👍 작성된 글 중간에 사용되는 이모티콘은 아래와 같이 사용하거나 사이트에서 복사하여 사용할 수 있다. 단축키 Window 10: Window Key(윈도우 키) + .(마침표) Mac: Command + Control + Space Bar사이트 https://emojipedia.org/ https://getemoji.com/ https://kr.piliapp.com/twitter-symbols/앞으로 Velog 글을 쓰기 위한 마크다운 작성법에 대해 알아봤다. 마크다운을 처음 사용 해보았는데, 적용하기 어렵지는 않았다. 그리고 점점 마크다운에 적응될 때마다 글쓰기 페이지에서 사용할 수 있는 기능이 늘어나면서 상당한 재미를 느낄 수 있었다.🙂end." } ]
